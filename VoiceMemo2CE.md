**ScottM:**

Hello. Hi, Caroline. This is Scott, obviously. I'm really sorry for missing our Monday meeting. I've been, and still am, in administrative duties hell—Monday, Tuesday, Wednesday—and then I returned to marking hell. So, I have done some work and wanted to try and update you. My typing is quite poor, and my spelling is even worse, so I thought it would be quicker just to send you a recording. Here’s a somewhat organized summary of where I'm at and what I was hoping to discuss with you on Monday. Again, I apologize for missing that meeting.

So, let’s bring it up. Here we go. I think the first thing for me when re-approaching this is to start with conceptualization and population, which I’ll call the setting. The first question is: what is the population? I think we have a very clear answer to that—it’s domestic workers in the UK. More technically, it’s domestic workers in the UK who have a mobile phone during the survey fielding. Maybe it’s domestic workers who have had a mobile phone in the calendar year preceding the survey fielding, something like that.

If that’s the population we’re sampling from, which I believe it is, then I think that’s very well defined, and that’s fantastic. The target population, this hidden population, so to speak, consists of domestic workers in the UK who have a cell phone and have experienced exploitation or modern slavery in the past 12 months. There are a few ways we can operationalize that. You and Selim, and a little bit myself, but really it was mostly you, have come up with three very principled ways to do this.

The first two are dichotomies. So, this would be Question 36 dichotomized. This is simply: “Do you get paid less than the legal minimum wage?” And Question 80 also dichotomized, which is: “Have you been through the National Referral Mechanism, or have you been referred to the National Referral Mechanism?” To my mind, these are both very high bars. If people answer “yes” truthfully to either of those questions, I think—and I'm not an expert in this field whatsoever—but I think we can be very confident that, yes, that person counts as a member of the hidden population.

I think that’s true. We also discussed—and you and Selim, mainly you, developed—a continuous measure. So here, the idea is conceptually different. In this third idea, which I think is called... sorry, I took notes, and clearly, I... this is like the sum categories or sum cut. The idea is that you developed a series of indicators—sounds like eight or 12 or 16—and we just sort of normalized them and said, “How many of these indicators?” And actually, there was a weighting to them, “Do you satisfy?” And then we were going to come up with some number between zero and one that represents your exposure to the risk of experiencing modern slavery.

So, if we use that as a measurement, as a separate measurement, as a continuous measurement—not of experiencing modern slavery, but of the risk of experiencing modern slavery—that might sound like I'm splitting hairs, but I think methodologically, in terms of dichotomies versus continuous, but more importantly, conceptually, those are quite different. Because in the latter case, if we claim that we’re measuring the risk of exposure, then I think the population needs to be a little bit redefined. The population we’re sampling from is still domestic workers in the UK who have a cell phone, yada, yada, yada. But in this third continuous operationalization of experiencing modern slavery—or more formally, risk, let’s call it a risk index, and I've called it like 24 different things, and I apologize—but in that world, we’re asserting that everyone in the population has some value of this variable. That is to say, everyone in the population—domestic workers in the UK that we’re sampling from—has some risk of experiencing modern slavery. That risk might be zero, okay, fine. But again, conceptually, I think that’s important.

So, I don’t know if that’s correct or not, but that’s where I'm at—that’s where I started. So, we’ve got the population, we’ve got the target population. Now, how are we sampling? Where is this data coming from? We spent a few rounds and months on this, but I think it was productive, although perhaps not what you wanted to hear, or I wanted to hear, or whatnot. But I think where we landed was, well, look, what do we have? We have a convenience sample. We have an RDS sample—a respondent-driven survey in which the respondents are members of the population. We’re sampling from domestic workers in the UK who have a cell phone, right? Yada, yada, yada. We’re sampling from that population. Initially, there are seeds, and then we’re doing an RDS with five coupons to branch out to do the RDS or the modified snowball—not exactly snowball—whatever.

Again, these are my beliefs, so please, right, correct me if I'm wrong. That’s the data we have to work with. Now the question is, what do we do with that data? I want to add one additional aspect to the sample, separate that from the data we’re talking about in a second. Functionally, the sample comes from three groups, or we’re sampling from three subgroups within the population of domestic workers in the UK who have a cell phone. Those are people from the Philippines—maybe they’re here on a visa, maybe they just identify as Filipino. Latinx, again by self-identified origin, ethnicity—I don’t remember the exact wording—and other, and British-born. That one, British-born, I think pretty sure is actually asked. I don’t have the question number on me. So, if we wanted to, we could say, okay, well, look, within this sample, there are three distinct clusters by nationality. I think we could assert that with veracity.

It’s been a long few days, and it’s only Tuesday. I apologize. So, these natural three subgroups or clusters—Latinx, Filipino, and British-born, I think. All right, that’s the sample. Let me... we’ve got... I hope you’re drinking a lot of tea or coffee and pausing and/or deleting this video. Before I get to the analysis, I want to address a few data issues. One, do we know anything about these sizes? Do we know anything about estimates of the number of domestic workers in the UK? I found two websites—one’s official, the UK’s nationalcareers.service.gov.uk job groups. They sort of... I'm guessing it’s census-based, but they have these job groupings. And another is from some organization in the UK called BICS—I’ve already forgotten what that stands for. But it looks like there’s some sense of the number of domestic workers in the UK. It depends on how you count—is this home cleaning, is it daycare, is it institutionalized, is it not? Like I said, this is just a very preliminary thing.

That’s one—numbers. One A—numbers. Actually, we could estimate the number of domestic workers in the UK from your very clever sample because of the RDS nature. One of the questions in the survey is, “How many other domestic workers do you know in the UK?” and then it asks for some recruitment information. But just asking the “how many.” So basically, what I'm saying is, we’re sampling from the population of domestic workers in the UK, and one of the questions is, “How many other people in this population do you know?” We can use that information to estimate the size of the population, where the population means domestic workers in the UK.

So that’s another... I’m exploring that currently as a possible additional source of information. By the way, that is using older... I’m just saying this for the record, sorry. So that’s using sort of the Guile et al., the early stuff—2010, 2011 stuff. The stuff we’ll talk about in a second for analysis is a bit later, 2014, 2015, a bit later. What I'm saying is, the population—we can try and estimate the size of the number of domestic workers in the UK, which might be of interest for a number of reasons. For me, it’s of interest because we need that number for later calculations, and that can come from a few sources. I found two online—maybe they’re valid, maybe they’re not. The third is, we could try and estimate that from your survey. I'm working on that currently, but it’s giving weird answers—like it’s way too small, and it’s taking way too long to run. So whatever, I'm just saying that for the record.

Now, I don’t remember what number we’re up to—analysis. Step one, let’s just take it from the literature. Let’s do the Guile et al. This is the so-called SSPS—successive sampling population size estimates. Krista Guile, who—again, small world—we were neighbors during our postdoc, comes up with this very clever way of exploiting additional information within RDS samples that essentially takes into account... What’s really cool about it is that it uses the wave at which you appeared in the sample as an additional piece of information. The idea being that those with larger personal networks—so, if I'm a seed and I give two recruits, odds are those two recruits have bigger social networks than, say, the other people that I didn’t recruit. Basically, that’s the idea, and so on and so forth.

So it uses this idea, which overcomes—it mitigates—a lot of biases that were in so-called RDS1 and RDS2. I’ve also seen it called RDSA and RDSB, volts, etc., etc., etc. So this SSPSC seems to be, as far as I can tell, pretty state of the art. So we can just take that from the literature. We can do estimation—there are a few hiccups, but nothing that we can’t overcome—and we get proportions. We get proportions of the population, which currently we don’t know the size of, but we can come up with some sensible ways of estimating it. That are experiencing—that are in the hidden population, that are experiencing modern slavery, however defined, via Q36 or Q80, both dichotomized, which again, to my mind, are very high bars. If you’re saying yes to either Q36 or Q80, again dichotomized, if you’re answering honestly, there’s very, very good reason to think that you’re a member of the hidden population—that you’re a domestic worker in the UK with a mobile phone that is being exploited, that is experiencing modern slavery.

We can do that, and there’s some very, very recent—most recent I found was the McLaughlin et al., 2023—I don’t even know if I’ve sent it around, sorry if I haven’t—that says, yeah, yeah, that’s great. But essentially, the number of people that I report... It’s really clever. It says basically, the number... I might not know the number of people that I know, so the number of people that I report shouldn’t be taken too literally. Essentially, what they do is they just add a measurement error component. They say, yeah, well, you might not actually know—you might not truthfully report the number of people that you know that are in your personal network, that are in our world, that are domestic workers in the UK that have such and such characteristics.

So we can do all that, and I have done that, and the answer is really high proportions—something like 30 to 40%, depending on which question we use, priors, which model, etc., etc. But pretty consistently 30 to 40%. Sorry, let me say it differently. Concurrent with the preliminary stuff I sent, whatever it was, months ago, something like 30-40% of domestic workers in the UK—if that’s the population—we are estimating to be experiencing modern slavery, again, depending on how we’re defining it. It’s one of these two dichotomous variables. There are caveats, however. I will say this—I was worried about a few things because when I first saw that, I thought, wow, that’s really high. So maybe there are some convergence issues—it doesn’t look like it. It looks like things have converged pretty well.

This is embarrassing. This reminds me that when I was younger, my parents would call me on voicemail, and sometimes my dad especially would just ramble, and the voicemail would cut off—he would have expired the maximum amount of time. I think that just happened to me—I’ve been rambling at you for more than the allotted time that Microsoft is letting me, and yet here I go again. So I’ll do my best to try and send along some kind of summary transcript. I'm sorry—this is me trying desperately to stay current and catch up on research, of which this is literally the number one priority, and you see that I'm already falling behind. So I'm really sorry about that.

Okay, right, blah, blah, blah. Where were we? So there are these estimates, and they seem... I believe them more than I did when I first sent the preliminaries around. Now, there’s still stuff to do—robustness, this, that, and the other—but these numbers seem pretty high. Okay, again, 30-40%, something like that. Now, there are a few caveats here—well, I need to say caveats. There are a few things I need to say.

The first is, I should have said earlier, isn’t about the analysis—it’s about the data and data cleaning. So, one thing, and much appreciation to Selim—he’s done a ton of work—but one is, and this turns out to be a bit of a subtle issue, at least in political science, so one is how do you deal with the “don’t knows”? Some of the questions, for example, one of our indicator questions about “Are you in this hidden population?”—“Are you experiencing modern slavery?”—is about referral to the National Referral Mechanism. And one of the response answers is “I don’t know.” So the issue is, how do you deal with those? And those “I don’t know” answers pop up, obviously, in lots of other questions.

Currently, in Selim’s formulation, they’re being coded as negative—“No, I’m not, whatever the question is asking.” Something just happened, oh my god, I feel like I'm one of the worst colleagues. I'm so sorry. An alternative approach is to classify them as missing. So essentially, you say, well look, if a person reports, “I don’t know if I've been referred to the National Referral Mechanism,” we’re just going to ignore you for purposes of analysis. We’re not going to count you as “No, I haven’t been referred.” So doing that actually weirdly increases, very slightly, the estimates of domestic workers in the UK experiencing modern slavery. So, Selim’s descriptive statistics were... If you do what I'm suggesting, which is to treat the “don’t knows” differently from either an affirmative or a negative, you get ever so slightly higher descriptive statistics—higher proportions just raw from the sample data. And it’s something, you know, it’s like 42-44, 42-43, or something like this. I mean, they’re not huge.

That’s one issue. Two—this one’s a bit trickier—17 out of 97 people in the sample report knowing zero domestic workers in the UK. One of the questions that—in fact, the question, I should be more clear, I'm sorry, Caroline, I'll try and clean this up in the transcript—in the summary of the transcript, they say, “I know zero people in the population,” which we’ve defined to be, if I'm thinking about this correctly, domestic workers in the UK. Right. Okay, so maybe they do, maybe that’s true, or maybe they don’t, but then in terms of this data cleaning business... But then some of them make referrals. So among the 17 that say, “I know zero domestic workers in the UK,” there’s another question that says, “Please give us the cell phone number of a domestic worker in the UK that you know, where ‘know’ is defined properly per your survey,” and they’ll give a cell phone number or two. Which again, this is a logical inconsistency. If you report a referral, and a referral must be a domestic worker in the UK, then you cannot know zero domestic workers in the UK.

So there are a few people in the survey like that. Essentially, what I'm saying is those zeros should actually be something positive. We don’t actually know, but a conservative answer would be to turn those zeros into ones. So I haven’t done that, but it’s a handful of people. I can’t imagine it’s going to matter, but there’s a larger issue, which is what to do with these zeros. So if a person in the sample claims they know zero domestic workers in the UK—and like I said, there are 17 or so out of 97, so it’s not nothing—what do we do with those? The reason I say that is because the estimators that I've been using essentially can’t handle the zeros. The reason for that—I hadn’t thought very deeply about it, but I guess it kind of makes sense in the following way—the estimators that we’re dealing with extensively rely on social network information. So if there’s a person in your sample that says, “I don’t have a social network—zero,” then that causes some problems because the entire estimation strategy of these different techniques is to exploit or use whatever social network there is. But if that’s zero, then something breaks. And to be honest, I haven’t worked through the math.

So what do we do with those? We could remove them—turns out that doesn’t really matter too much. We could try other techniques—I haven’t fully explored that. I’ve explored that a little, and I don’t really know what to make of it. Or we could just really add hoc—just add one to everybody’s reported degree. So all the zeros turn into ones, all the fives turn into sixes. That’s not principled whatsoever, but it’s another approach. Okay, so that’s data stuff.

All right, now, with regard to results—which again, I've completely misordered this, and hopefully, it will be temporarily correct in the accompanying outline, should I get around to producing it—so this 30-40% business that I mentioned earlier, like I said, I believe it more than I did when I sent you the initial preliminary results, which were relatively similar. The little convergence results—so we have this estimate that’s doing a lot of math. The idea is it comes up with lots and lots and lots of estimates, but when all these estimates get very, very close to each other, the algorithm stops and says, “Okay, here it is.” So you can look and see, does it actually do that? The answer is yes. It converges.

So I'm relatively... I'm more confident in the numbers on resolve that. Okay, so what am I... I'm sorry, I need to look at... right. So the number one is just, do we believe these results? I’ve checked convergence preliminarily, it looks pretty good. We could do sensitivity analysis—that would be on me. I’ve done a little bit of that, and again, it seems, in my opinion, surprisingly robust. I don’t remember my discussion about frequentist versus Bayesian, but the idea is you put some prior information into this estimator, like, for example, how many domestic workers are there in the UK? What is the size of the population? Now, we don’t know that number, but we have some belief about it. The beliefs I’ve been using are something like 1.74 million, say 2 million, whatever. So you can change that number, and the resulting estimates are very, very similar—again, in this 30-40% range.

There are other techniques. The techniques I've been using all assume that the graph is connected. What that means is that if we were to know everybody’s social network—which we don’t—but if we were to know all of it, it’s connected. Functionally, what that means is that if there’s an Ecuadorian in our sample, that truly, if we had the entire social network of all domestic workers in the UK—which we don’t—if we did, there’d be some path from that domestic worker from Ecuador to any other person, any other domestic worker in the UK—in particular, to the Filipino worker who might be in our sample or might not, to the British-born, the British national, whatever. So truly, they’re all connected. Now, I think I mentioned this, but there are reasons to think that might not be true, that there really might be clusters or subgroups here, primarily around language, I would guess. Again, I'm not an expert, but... so that’s fine.

There are techniques to deal with that. We could, and I haven’t, but we could pretty straightforwardly deal with, well, maybe there’s a Filipino network, and maybe there’s a Spanish-speaking network, or maybe there’s a UK-born network, and maybe those are different. Maybe they’re not—maybe they’re all connected. But we could... one might say, well, I don’t really think that they’re all connected. So that’s fine—we can deal with that. I haven’t, but we can. Okay, so that’s one thing—disaggregate by origin. We got that. Like I said, it’s, in my opinion, shockingly high. So, you know, there’s the whole, do we believe it?

Oh, and then... right. So then there’s an entirely separate, to my mind, third sort of approach or strata estimation strategy, which is so far everything I've talked about is sort of off-the-shelf RDS. It’s very sophisticated and involves tweaks like visibility and measurement error, yada, yada, yada, yada, but it’s very... our sample is RDS, and we’re trying to estimate the size of some population/hidden population/members of the population with some particular categorical attribute, etc., which again, perfectly fine, fits the data fantastically. It’s not at all what I thought we initially started this project with, which was some variant of in-sum or network scale-up—in particular, your very, very cool and very novel idea to use the generalized GNsum here.

So the question is, can we use the data that we have to do some kind of in-sum-ish estimation? The reason I'm sort of pushing this or advocating for this is because I think it’s much more... my guess is it’s going to be much more powerful because in-sum is using more information. And it’s not just counting the number of... well, how do I say this... so in-sum is very, very powerful. The issue is, if you don’t have a random sample, what do you do about that? The answer is lots of weird math that essentially boils down to the linchpin for us—what’s called inclusion probabilities. We don’t have a random sample, we acknowledge that, that’s fine. So what statistical tricks can we do to the data that we have in-sample so as to be able to justify and use techniques that are meant for analysis of random samples, like in-sum?

So there’s an answer to that, and the answer is weighting. I think there are some really, really nice intersections here, and it’s really pretty straightforward. I haven’t implemented them, but essentially we can derive weights from these RDS estimators and logic and packages in R to come up with these inclusion probabilities. Again, we can do a few robustness whatever, and then use those in the in-sum calculations. I haven’t done that, but I'm really excited to do that because I think... my hunch is that’s going to be much more powerful in that it’s sort of taking the best—it’s squeezing all the information that at least I am aware of—out of the data that we actually have.

Okay, I've been rambling. Combined with that... so I haven’t done that. So, Scott Moser to do: bootstraps—I’ve done some, I haven’t done all of them; sensitivity analysis—again, some, not a bunch; this third way—this in-sum plus RDS weights—I’m very excited about, haven’t touched it, I haven’t touched it practically. I have thought about it and have notes, which are a mess.

Next topic: presentation. What do we want to present? And how do we want to present it? Tables, graphs, distributions, confidence intervals, Bayesian plus series, what? I don’t know. And if I'm being perfectly honest with you, Caroline, I'm not really... right now, I'm not in a huge position to sort of produce publication-ready graphics or what have you. But I think that’s a discussion that would help me, at least.

Okay, I think I'm about to get cut off again, so I'm going to stop. This is what I was hoping to report, discuss, talk about with you on Monday. Like I said, I utterly failed. Hopefully, this has some meaning.
