---
title: "Quantifying Hidden Exploitation: Dual-Method Prevalence Estimates of Modern Slavery Risk Among UK Domestic Workers^[Authors' names are listed in alphabetical order.]"
author:
  - name: Caroline Emberson
    affiliation: UoN
  - name: Scott Moser
    affiliation: UoN
date: today
date-format: "DD, MMMM YYYY"
abstract: |
  Purpose
  
  The purpose of this article is to demonstrate a quantitative approach to the construction of a risk index of labour exploitation and alternative estimators of the prevalence of exploitation.
  
  Design/ Methodology/ Approach
  
  Using data from a survey of domestic workers based in the United Kingdom (UK), we use statistical techniques, including Respondent Driven Sampling (RDS) methods RDS-I and RDS-II and Network Scale Up (NSUM) methods, to produce an index of labour exploitation risk and estimators of the prevalence of labour exploitation.
  
  Findings
  
  The labour exploitation risk index shows a reverse correlation between the increasing seriousness of exploitation and the number of exploitation cases reported.
  The various prevalence estimators examined show significant differences in population level exploitation.
  
  Research implications/ limitations
  
  Further research into the application of different quantitative statistical estimators of the prevalence of labour exploitation is urgently required. 
  
  Practical implications
  
  Robust estimators are necessary if policy makers are to make informed choices about the appropriate allocation of scarce resources to help to eradicate severe forms of labour exploitation and labour abuse.
  
  Social implications

    Even by more conservative estimates, thousands of domestic workers in the UK are subject to labour exploitation. Urgent policy attention is needed if structural vulnerabilities are to be removed.

  Originality

  We believe this paper is the first to compare the use of RDS and NSUM methods in the quantitative estimation of the prevalence of labour exploitation and to construct a quantitative, composite index of labour exploitation risk. 

  
bibliography: 
  - references.bib
  - MyLibrary2025-08-25.bib

fontsize: 12pt
geometry: margin=1in
subparagraph: true
format:
  pdf:
    pdf-engine: xelatex
    cite-method: biblatex
    keep-tex: true
    biblatexoptions:
      - backend=biber
      - natbib = true
      - style=apa
      - sorting=nyt
      - maxcitenames=2
    include-in-header:
      text: |
        % Do NOT load biblatex here.
        \DeclareLanguageMapping{english}{english-apa}
        \usepackage{amsthm}
        \usepackage{amsmath}
        \usepackage{amsfonts}
        \usepackage{amssymb}
        \usepackage{float}
        \usepackage{caption}
        \usepackage{subcaption}
        \usepackage{stmaryrd}
        \usepackage{pdflscape}  % ADD THIS for landscape pages
        \theoremstyle{plain}
        \newtheorem{theorem}{Theorem}[section]
        \newtheorem{proposition}[theorem]{Proposition}
        \theoremstyle{definition}
        \newtheorem{definition}{Definition}
        \newtheorem{corollary}{Corollary}
        \newtheorem{example}{Example}
        \renewenvironment{proof}
           {\par\noindent\textbf{Proof.}\ }
           {\hfill$\blacksquare$\par}
        \usepackage[ruled,vlined,linesnumbered]{algorithm2e}
    number-sections: true
    toc: true
    toc-depth: 3
    colorlinks: true
    linkcolor: black
    citecolor: RoyalBlue
    urlcolor: BrickRed
    link-citations: true
    fig-pos: "H"
    fig-width: 6.5    # Good default
    fig-height: 4     # Good default
    df-print: kable
    pandoc:
      from: markdown+tex_math_dollars+tex_math_single_backslash
  docx:
    number-sections: true
    highlight-style: github
    fig-width: 6      # CHANGE to 6 for DOCX
    fig-height: 4
    fig-dpi: 300      # ADD this
    df-print: kable   # ADD this
  html:
    code-fold: true
    toc: true
    toc-depth: 3
    theme: cosmo
    fig-width: 10
    fig-height: 6
editor:
  markdown:
    wrap: sentence
execute:
  warning: false
  message: false
  eval: true
---

```{r setup, include=FALSE}
getwd()
## Ensure fs is available
if (!requireNamespace("fs", quietly = TRUE)) install.packages("fs")

# Set PDF-friendly graphics options
if (knitr::is_latex_output()) {
  # Set device to cairo_pdf for better font handling
  knitr::opts_chunk$set(
    dev = "cairo_pdf",
    dev.args = list(family = "", fallback_resolution = 300),
    fig.retina = 1
  )

  # Set ggplot2 default theme with safe fonts
  if (requireNamespace("ggplot2", quietly = TRUE)) {
    ggplot2::theme_set(ggplot2::theme_minimal(base_family = ""))
  }
} else {
  # For HTML output
  knitr::opts_chunk$set(
    dev = "png",
    dpi = 300
  )
}

## Define paths
home_dir <- Sys.getenv("HOME")
bib_source <- fs::path(home_dir, "Dropbox", "Bibliog", "scottAll5-BBL-URLdoi2024.bib")
bib_target <- "references.bib"

## Only copy if target doesn't exist or source is newer
if (!fs::file_exists(bib_target) ||
    fs::file_info(bib_source)$modification_time > fs::file_info(bib_target)$modification_time) {
  fs::file_copy(bib_source, bib_target, overwrite = TRUE)
  message("- Updated bibliography file")
} else {
  message("- Bibliography file is up to date")
}

## Rest of your setup...
css_dir <- fs::path(home_dir, "Dropbox", "LaTeX", "Stationary", "Rmakrdown")
css_files <- c("columns.css", "seminar_v6.css", "Qmd_noPublished.css")

fs::dir_create("css")
for (file in css_files) {
  source <- fs::path(css_dir, file)
  target <- fs::path("css", file)
  if (!fs::file_exists(target) ||
      fs::file_info(source)$modification_time > fs::file_info(target)$modification_time) {
    fs::file_copy(source, target, overwrite = TRUE)
    message(paste("- Updated", file))
  }
}

## Download CSL file if missing
if (!fs::file_exists("apa.csl")) {
  download.file(
    "https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl",
    "apa.csl"
  )
  message("- Downloaded APA citation style")
}

message("Setup complete!")

library(here)
load(here("data", "processed", "prepared_data.RData"))
prepared_data <- dd
```

<!-- NOTES: (1)custom placement of Endnotes only works for `html_document(2)` -- not pdf_document   (2) boxes added -> uses `\usepackage{framed}` for LaTeX-ing -- see https://bookdown.org/yihui/rmarkdown-cookbook/custom-blocks.html  (3)    -->

<!-- As discussed in the [this footnote](#footnote1)  the results are significant.[^11] -->

<!-- [^11]: <a name="footnote1"></a>Your detailed footnote text goes here. -->

<!-- https://tex.stackexchange.com/questions/452552/algorithm-pseudocode-in-markdown -->

\newpage


<!-- ```          -->
<!-- * Why study labour exploitation among UK domestic workers? -->

<!-- * Gap in existing research. -->

<!-- * Contributions: (1) Conceptualisation of exploitation (binary vs. continuous, risk index), (2) Novel use of dual methods (RDS & NSUM), (3) Policy relevance. -->
<!-- ``` -->

```{=latex}

\section{Introduction}\label{introduction}

Labour exploitation has been defined as `work situations that deviate 
significantly from standard working conditions as defined by legislation
or other binding legal regulations, concerning in particular
remuneration, working hours, leave entitlements, health and safety
standards and decent treatment'\autocite[10]{european_union_for_fundamental_rights_severe_2015}. In the operations and supply chain management literature,
interest in businesses' respect for these kinds of employee labour rights began with
studies focused upon labour rights transgressions related to risk
reduction and risk communication and how to improve
employees' health and safety \autocite{chinander_aligning_2001,wolf_operationalizing_2001}. More recently, 
serious labour rights abuses have come to the fore with studies
examining the challenges of severe labour exploitation under the umbrella term `modern slavery' \autocite{gold_modern_2015,new_modern_2015,benstead_horizontal_2018,stevenson_modern_2018}. While this literature
offers important insights into severe forms of labour exploitation, particularly
in global supply chains, this and the wider social sustainability literature has
been criticised for its de-humanised approach to the understanding
of workers and their working conditions \autocite{soundararajan_humanizing_2021}. While at least one current
project seeks to examine the phenomenon of worker voice in factory
settings  \autocite{leverhulme_trust_research_2022}, there appears to be little attention paid to severe forms of labour exploitation from the workers' perspective in the private sphere. Nowhere are the realities of individual workers' experiences of employer exploitation brought into sharper relief than in the setting of domestic
work in private households.

The authors of the Global Slavery Index estimate that there are
seventy-six million people employed in domestic work worldwide
\autocite{international_labour_organization_global_2022}).
According to \textcite{bonnet_domestic_2022}, eighty percent of this domestic work is unregulated and informal. Labour
exploitation has been identified as an extensive global problem within
the sector, with domestic work identified as one of five private sector
groupings which contribute the most to forced labour. Defined in the ILO
Forced Labour Convention, 1930 No.29, forced or compulsory labour is
`all work or service which is exacted from a person under the threat of
a penalty and for which the person has not offered himself or herself
voluntarily' \autocite{ilo_what_2024}. Seventy-six
percent of domestic workers are women, and these workers represent four
percent of the total female workforce \autocite{international_labour_organization_global_2022}. Indeed, women in forced labour are much more likely to be in domestic
work than in any other occupation \autocite{international_labour_organization_global_2022}.
The ILO suggest that female domestic workers may be coerced through
non-payment of wages; abuse of vulnerability; subjected to physical and
sexual violence or experience threats against their family members. Such
severe forms of labour exploitation may be present alongside other,
perhaps less severe but equally illegal, practices which constitute
various forms of labour abuse. The criminalisation of both labour
exploitation and abuse in a domestic setting has developed in recent
times, with legislation enacted in the United Kingdom (UK), Europe,
Australia and Norway to criminalise such severe exploitation under the
term `modern slavery'. However, even where modern slavery laws are in
place, reliance on traditional, inspection-led, approaches to detection
designed primarily to ensure labour rights compliance within communal
workplaces such as factories mean that the number of reported cases of
labour exploitation in private dwellings may well severely underestimate
actual exploitation levels. Though an exploration of labour exploitation within private residences, our research seeks to redress the paucity of rigorous quantitative research in the modern slavery field.  Specifically, this article aims to contribute to a more
nuanced understanding of how quantitative methodologies may be deployed to
improve understanding of the realities of workers' conditions by
demonstrating the use of a statistically robust estimation of the nature
and proportion of labour exploitation and abuse among domestic workers in the UK. This setting was chosen due to long-standing national
legislation criminalising modern slavery introduced to the UK in 2015.
Despite, or perhaps because of this legislation, in recent years the
number of potential victims entering the UK's National Referral
Mechanism (NRM), a scheme which provides government support for those
suspected to be modern slavery survivors, has continued to increase.
Nineteen thousand, one hundred and twenty-five potential victims were
recorded in 2024: the highest annual figure since the NRM began
\autocite{home_office_modern_2025}. In 2024, for the
first time the number of cases of potential modern slavery among females
handled by the charity Unseen, who run the UK's modern slavery helpline,
were more prevalent than those among men 
(\cite{carter_women_2025}). Despite these worrying
headline statistics, and the persistence of specific concerns about high
levels of exploitation among domestic workers in the grey literature
\autocite{kalayaan_new_2008, mantouvalou_modern_2016, latin_american_womens_rights_service_behind_2023}, to our knowledge no-one has yet estimated the nature and extent of labour exploitation and abuse that may exist among domestic workers in the UK.

In contrast to overseas factory workers in globally dispersed, product,
supply chains, many service workers engaged in domestic work have
migrated to work in the UK. These transnational workers enter on
restricted visas where their employment---and their right to remain in
the country---is tied to their continuing employment. It is now ten
years since the UK's Modern Slavery Act was enacted. During its passage
through parliament, those advocating for the rights of domestic workers
were successful in expanding the final category boundaries of the
legislation to include, in Section 53, the specific definition of
(overseas) domestic workers as modern slavery victims 
\autocite{caruana_boundaries_2025}. These transnational
migrants are at particular risk of exploitation due to regulatory visa
restrictions and intersecting structural issues related to their gender,
the relative isolation of domestic work and a lack of supportive social
networks. This can mean that they fall out of legal migratory status.
Due to the social stigma attached to such illegal working, transnational
workers remaining in the UK without the right to work may be considered
a hidden, hard-to-reach, population. Extracting a sample of domestic
workers which includes this group raises difficulties when trying to
employ the normal statistical sampling methods considered necessary for
robust prevalence estimation. Perhaps due to these sampling
difficulties, we know relatively little about the nature of labour
exploitation among this particularly at-risk group of workers.
Fortunately, there has been significant interest in the development of
alternative methods for prevalence estimation which include such
hard-to-reach groups, with many scholars advocating and developing the
use of respondent-driven sampling (RDS) techniques to support
statistically robust estimators.

In this paper, we make two specific contributions to the operations and
supply chain management literature. First, we demonstrate the use of RDS
coupled with Network Scale-up Methods (N-SUM) to reach and sample
respondents' views of their working conditions among these,
predominantly female, transnational migrant domestic workers. We use the
data we obtain from these respondents to show how quantitative survey data can be
used to estimate the proportion of workers experiencing labour
exploitation. Second, we begin to capture the nature and extent of
modern slavery as voiced by domestic workers, thus, we
believe, expanding the nascent literature on worker voice which has, in
the main, focused primarily on factory workers
\autocite{stephens_theorising_2024}. These contributions
not only extend our understanding of the risks of labour exploitation
and abuse among service workers engaged in domestic settings but also
show how it is possible to shed light on the severity of the
individuals' experience of exploitation through the construction of a
novel risk index. The remainder of this paper is structured as follows.
our study in more detail, highlighting what is already known about the
current population of domestic workers in the UK and the conditions in
which they work. Next, we describe our research methods. We review the
development of the respondent-driven sampling (RDS) techniques we used
and explain why this sampling method is suitable for our study. We then
describe our survey methods, including how we designed our survey
instrument, contacted our sample seeds and analysed our data. We then
present and discuss our findings, detailing the proportional estimate
that we calculated and the risk index we constructed. In our discussion,
we expand upon the implications of our findings for government policy,
enforcement practices and further research, including how these methods
may be used in future studies of labour exploitation in other sectoral
and geographic contexts. The limitations of our study are outlined,
before, finally, we conclude our article.
```

### Conceptualising Labour Exploitation and the Degree of Risk

-   Binary vs. continuous definitions.

-   Risk index construction and theoretical justification.

Modern slavery has been criticised by some for its overly extensive scope: encapsulating a broad range of divergent sub-categories of exploitation (@oconnell_davidson_margins_2015; @gutierrez-huerter_o_change_2023).
For this reason, we used the International Labour Organization’s (@ILO11-indicators) ‘Indicators of Forced Labour’ to identify the potential for severe labour exploitation and as a basis for the quantification of our labour exploitation and abuse risk index.
The ILO identify eleven indicators designed to help understand how forced labour arises and how it affects victims.
These indicators include: abuse of vulnerability; deception; restriction of movement; isolation; physical and sexual violence; intimidation and threats; retention of identity documents; withholding of wages; debt bondage; abusive working and living conditions and excessive overtime.
According to the ILO, the presence of a single indicator in any given situation may in some cases imply the existence of forced labour.
However, it also suggests that in other cases it may be necessary to look for several indications which, taken together, may point to a case of forced labour.
We seek to refine this statement through the construction of a composite index by which means a degree of risk related to the likelihood of a domestic worker experiencing this most severe form of exploitation may be distinguished from the likely occurrence of less severe, though similarly illegal, forms of labour abuse.


## Evaluating the Degree of Risk

The study of risk management has a long tradition in operations and supply chain management.
Initially, the risks under consideration were primarily related to ensuring continuity of the supply of goods and services (see for example, @juttner_supply_2003).
Beginning with @anderson_critical_2006 and @anderson_sustainability_2009, however, a literature stream of sustainability-related supply chain risk management developed related specifically to the risks associated with the environment and social justice.
A normative consensus related to the main stages of supply chain risk management has developed in the literature, with a five-stage sequential model typically presented.
There have also been empirical studies of risk management within various industrial supply chains in the United States and India (@tarei_hybrid_2018; @dellana_scale_2021), including the quantification of a risk index for the petroleum supply chain (@tarei_hybrid_2018).
Yet, while these authors recognize the need for responsible management and its effect on societal values, in line with other literature in the field they view risk from the perspective of the corporate supply chain rather than examining the risk of harm to the worker.

In our study, we conceptualise the risk of labour exploitation from the workers’ perspective.
We conceive severe forms of labour exploitation such as forced labour as one end of a spectrum ranging from illegal employment practices that constitute labour abuse, such as wage payments below legal minimum wage levels and health and safety violations, through to the likelihood of criminal exploitation recognized in the UK as modern slavery.
Our assessment of this personal risk permits a degree of risk to be assigned to various clusters of forced labour indicators with the more indicators present, the stronger the likelihood that the working conditions may be considered exploitative.
Our approach, therefore, includes, but goes beyond, assessing the likelihood of forced labour by simply quantifying the proportion of survivors entering the UK’s National Referral Mechanism (NRM): a government system for survivor support set up to identify whether there are positive grounds for the identification of Modern Slavery.
In our method, an NRM referral is used as the strongest indicator of modern slavery risk, with lesser risks assessed according to the degree to which cumulative indicators of forced labour are reported.

### Case Setting: Labour Exploitation Risk Among Transnational Migrant Domestic Workers In The UK

Domestic work forms part of a broader industrial category of Personal and Household Service work (PHS).
Work in this category includes those employed in ‘social work activities without accommodation’ and ‘activities of households as employers of domestic personnel’ (@european_commission_staff_2012).
In 2017, an estimated 980,000 people were engaged in PHS work in the UK (@manoudi_analysis_2018).
@manoudi_analysis_2018 highlight that the PHS sector is dominated by women and migrants, with many undeclared foreign workers.
Detailed statistics related to the country of origin of domestic workers migrating to work in PHS in the UK are difficult to isolate before 2019.
Since that time, annual migration has fluctuated – falling sharply in 2021 due in part to the COVID-19 pandemic, before later rising again above pre-pandemic levels.
In the year to December 2022, the UK Home Office reported that it had issued 18,533 Overseas Domestic Worker visas (@home_office_why_2023).
These domestic workers came from various countries in South America and Asia, including many from the Philippines.

In 2023, @strauss_britain_2023 reported a big shift in the source countries of migrants arriving in the UK on the Overseas Domestic Worker and other types of worker visas.
Transnational domestic workers from the Philippines and India accounted for the single largest number of applications granted (10,186 and 3,858 visas respectively), followed by smaller, but still significant, numbers of workers arriving from Bangladesh (465), Nigeria (446), Sri Lanka (444), Egypt (422), and Ethiopia (285).
In the same period, smaller numbers of visa applications to work as a domestic worker in the UK were also accepted from workers from other source countries including, but not limited to, the Sudan, Nepal, Ghana, Kenya, Lebanon, Eritrea, Iran, Turkey, Yemen, Malaysia, Thailand, and Morocco.
This post-Brexit increase in the diversity of source countries from which transnational workers are drawn makes a more detailed analysis of the risk of labour exploitation in the sector both timely and more urgent.

There is a long history of reports of exploitation in the domestic work sector in the UK.
In 2008, the civil society organisation Kalayaan, which was formed to campaign for the formal recognition of migrant domestic workers’ rights in the UK, reported on the impact of proposed changes to the UK immigration system on migrant domestic workers (@kalayaan_new_2008).
Their report highlights government recognition of documented and unacceptable levels of abuse and exploitation among domestic workers in the UK as early as 1996.
At this stage, new policies, including the development of a specialised visa allowing domestic workers to change employer during their stay were introduced.
However, in 2012, these visa conditions were modified, tying domestic workers to a single employer and restricting the length of time that they are permitted to remain in the country to a period of six months (@gower_calls_2016).
Overseas domestic worker visa holders are now, again, permitted to change employers, but not to apply to renew their six-month long visa unless they receive a positive ‘Conclusive Grounds’ decision related to exploitation considered to be modern slavery through the UK’s National Referral Mechanism (NRM) (@romero_blueprint_2025).

These reports highlight the underlying reasons for migrant domestic workers’ vulnerability, including workers’ relative desperation for work; their lack of social ties; unfamiliarity with English language and culture; long working hours; lack of knowledge of their legal rights; a lack of oversight of the private home as a workplace; their work forming part of the informal economy; their reliance on their employer for permission to work in the UK; and their lack of recourse to public funds.
As a result, migrant domestic workers are vulnerable to abuse ranging from minor breaches of employment and health and safety law, to physical and sexual violence, slavery, forced labour and trafficking.

That these conditions may persist is evidenced by a report from another civil society organisation, the Latin American Women’s Rights Service, which describes the results from twelve in-depth interviews with Latin American domestic workers in the UK.
This report depicts high levels of isolation, exploitation and abuse including a failure by employers to provide written contracts or payslips; breaches of verbal agreements; a requirement to perform different tasks from those indicated during recruitment; increasing working hours with little or no time off; excessive work days; a lack of paid holiday; many domestic workers not registered with a GP; sexual harassment in the workplace; verbal or physical abuse; employer surveillance; a lack of opportunity to change working conditions; isolation and fear of seeking help; and high reported levels of trafficking for labour exploitation (@latin_american_womens_rights_service_behind_2023).

Against this backdrop, we used respondent driven sampling (RDS) as a sampling technique to recruit and survey domestic workers in the UK about the working conditions they were experiencing to estimate the nature and scale of abuse and exploitation based upon reports of their conditions by domestic workers themselves.

## Research Methods

<!-- ```          -->
<!-- * Survey and RDS design. -->

<!-- * Sample recruitment and incentives. -->

<!-- * Estimation methods (RDS estimators, NSUM, bootstrap). -->
<!-- ``` -->

### Respondent-Driven Sampling (RDS) And Survey Method

Comprehensive descriptions and literature reviews of the development and use of RDS to estimate the population size of a hidden population are available elsewhere (@heckathorn_comment_2011; @gile_methods_2018).
Suffice it to say, the possibilities of the use of a one-wave snowball sampling to allow researchers to obtain a sample of personal networks was posited by @frank_estimating_1994.
Following the identification of a set of original sample members known as seeds, @heckathorn_respondent-driven_1997; @heckathorn_respondent-driven_2002 advocate the use of a double incentive to recompense participants not only for their involvement, but also for their recruitment of further participants in subsequent ‘waves’ of participation by drawing upon the social ties through which members of the hidden population are connected to each other.

The typical number of original sample seeds is between two and ten: chosen as heterogeneously as possible (@gile_methods_2018).
Though they may be subject to both systematic and non-systematic errors, the use of snowballing methods for the study of hidden populations, with the support of monetary or symbolic rewards, has been advocated as a way of creating robust recruitment embodying diversity in characteristics such as ethnicity, gender and geographical location (@heckathorn_respondent-driven_1997; @heckathorn_respondent-driven_2002).
In these papers, Heckathorn advances the development of RDS to include self-reported network size as a population estimator and bootstrapping techniques to support the development of an estimator’s confidence intervals, an approach that has since been refined by others (@gile_network_2015).
Such developments derive a new class of indicators for the population mean and define a corresponding bootstrap method to estimate the errors in RDS.
The resulting ‘network working model’ permits the individual’s connectedness in the network to be tested, while reducing bias with respect to the composition of the seeds.
Snowball sampling is based upon the initial recruitment of the original sample selection by means of convenience.
RDS also takes a non-random approach to seed selection, but relies upon the social network structure that exists between participants to produce a non-probabilistic sample (@goodman_comment_2011).
Incentive structure is important—though this weakness is not a feature of our target hidden population, some researchers have identified that younger men with higher socio-economic status are less likely to participate (@mccreesh_respondent_2013).
Perhaps of more concern, RDS has been described as a risky strategy since researchers cannot be sure whether enough respondents have been recruited through subsequent waves to eliminate bias within the original sample members (@vincent_estimating_2017).

RDS has been widely used to sample a variety of hidden populations, including HIV prevalence, rape and client-initiated gender-based violence among sex workers (@mccreesh_evaluation_2012; @schwitters_prevalence_2012).
While the RDS method has proved limited when seeking to provide population heterogeneity by geographical location (@mccreesh_evaluation_2011), where these population features are of lesser importance, such methods have been used successfully.
RDS methods have been used to survey other migrant populations (@tyldum_surveying_2021), while such network-based referrals have been described as the only viable method to reach many types of labour trafficking victims (@zhang_measuring_2012) and have been used to research exploitation among low-wage workers in three American cities (@bernhardt_broken_2009); a study of labour trafficking in migrant communities in the city of San Diego (@vincent_estimating_2017); examination of the worst forms of child labour in the Indian state of Bihar (@zhang_victims_2019); and the commercial sexual exploitation of children in Nepal (@jordan_overcoming_2020).

The survey instrument included modules on demographic and employment characteristics, social network size and composition, and indicators of labour exploitation.
The exploitation indicators were based on the International Labour Organization’s framework of forced labour, adapted for the UK domestic work context.
These indicators allowed us to operationalise exploitation in two ways.
First, we constructed binary indicators classifying respondents as exploited or not exploited, based on threshold criteria.
Second, we developed a continuous risk index, designed to capture gradations of vulnerability across the full sample.

In the following section, we describe our methods, including how we designed our survey, contacted our sample seeds, and analysed our data.
Our approach can best be described as Web-based RDS (@wejnert_web-based_2008).
We designed a web survey using the JISC online survey interface, suitable for our respondents to complete via a mobile phone.
Composite measures to quantify the extent to which respondents were at risk of labour exploitation, including severe forms of exploitation such as forced labour, were constructed from existing exploitation typologies, notably the ILO’s Indicators (@ILO11-indicators).
The survey consisted of these 11 composite indicators and included questions related to domestic workers’ level of job satisfaction, employment conditions, and demographic data such as nationality, age, and gender.
The main survey was conducted in the five months between February and July 2023.

### Initial Sample Selection

We selected our first wave of participants nonrandomly by convenience sampling.
Mobile phone numbers were used both to identify seed participants and to act as a unique identifier for those whom they referred.
To avoid sample homophily, original sample members were selected from three distinct domestic worker communities.
This was facilitated by civil society organisations who represented distinct domestic worker communities.
One was an exclusively online community of transnational domestic workers working in the UK, the second represented UK domestic workers of Filipino origin, and the third drew its membership from the Latin American community of domestic workers, also in the UK.
Along with other academics with expertise in exploitation within domestic work, representatives from these three organisations also contributed to survey question design and facilitated the piloting of an initial version of the survey (which was translated and made available in four languages: English, Spanish, Tagalog, and Portuguese) to selected domestic workers within each community.

### Survey Incentives: Incentive Design and Participation Verification

A double incentive scheme rewarded respondents both for completing the questionnaire and for each referral who went on to engage with the survey.
The challenge of incentive design is to set the incentive at a level that adequately rewards respondents’ time and participation, but that also avoids the risk of fraudulent participation due to too high a monetary gain (@jordan_overcoming_2020).
A sum of £10 was provided for survey completion with a further £5 for each successful nomination.
While respondents were asked to nominate up to 10 domestic workers within their existing social network, it was the first three of these from whom participation was requested in subsequent waves.
This approach is akin to the use of vouchers in face-to-face studies as advocated by @thompson_new_2020.

The ethical and practical issues related to the design and effective use of incentives for RDS among vulnerable populations has been much discussed in the literature; see, for example, @wang_respondent-driven_2005; @abdul-quader_effectiveness_2006; @singer_incentives_2006; @dejong_ethical_2009; @semaan_ethical_2009; @brunovskis_untold_2010; @semaan_time-space_2010; @platt_adapting_2015, including the specificities of incentive use within web-based surveys (@cobanoglu_effect_2003).
Following the principles of lottery use established by @brown_you_2006 and @laguilles_can_2011, we also designed our survey to encourage the maximum extent of participation by entering all respondents completing the questionnaire into a free prize draw for £150.
Research suggests that a high lottery provides the most cost-effective incentive for obtaining complete responses (@gajic_cost-effectiveness_2012).
While using incentives to encourage participation would seem to be desirable, it is worth noting the potential downside of respondents fabricating responses to increase their remuneration (@robinson_sampling_2014).
To minimise this risk, mobile phone numbers for each respondent and those whom they referred were collated, and each of these numbers was called by one of the authors of the paper to ascertain the veracity of the respondent as a migrant domestic worker.

### Descriptive Statistics

In total, we received completed online surveys from 97 respondents.
Of these respondents, 90 identified themselves as transnational migrants.
Forty-five percent regarded themselves as self-employed, 39% identified themselves as employees, and 16% categorised their employment status as that of a worker.

Of the 97 respondents, 64 (66% of the total), and the largest single nationality group, reported that they had a Filipina background.
Other nationalities represented included Dominican, Brazilian, Spanish, Colombian, Bolivian, Venezuelan, Cuban, and Panamanian.
Female domestic workers made up 97% of the sample, with 3% of the sample comprised of male domestic workers.
The age structure of the domestic workers was skewed towards those over 45 years old, with such workers representing over half of the sample (see Table 1).

Recruitment diagnostics indicate that equilibrium was reached across key demographic variables by wave X.
Reported personal network sizes ranged from X to X, with a mean of X and a standard deviation of X.
Figure 1 presents the recruitment tree, showing that Latinx respondents generated longer referral chains, while British respondents tended to form shorter, more fragmented networks.

```{r}
#| label: fig-rds-network
#| fig-cap: "RDS Network Structure: Recruitment chains showing seed nodes (triangles) and recruit nodes (circles). Node colors represent nationality clusters, with node size proportional to out-degree (number of recruits). Lines show recruiter-recruit relationships. Source: Authors' Own Work."
#| fig-width: 9      # REDUCE from 12
#| fig-height: 6     # REDUCE from 8
#| out-width: "95%"  # ADD this
#| echo: false

# Load packages individually to avoid namespace conflicts
suppressPackageStartupMessages({
  library(dplyr)
  library(stringr)
  library(igraph)
  library(ggraph)
  library(ggplot2)
  library(RColorBrewer)
  library(here)
})

# Load the prepared data
load(here("data", "processed", "prepared_data.RData"))

# Set PDF-friendly options for this chunk
if (knitr::is_latex_output()) {
  # Use cairo for PDF output to handle fonts better
  old_theme <- ggplot2::theme_get()
  ggplot2::theme_set(ggplot2::theme_void(base_family = ""))
}

# Create nationality clusters from q8_a
data_viz <- prepared_data %>%
  dplyr::mutate(
    nationality_cluster = dplyr::case_when(
      stringr::str_detect(q8_a, "Filipino") ~ "Filipino",
      stringr::str_detect(q8_a, "Boliviana|Brasileira|Brazilian|Colombiana|Dominicana|Ecuadorian|Española|Latin American|Latín spanish|Mexicana|Panama|Spanish|Venezolana") ~ "Latinx",
      stringr::str_detect(q8_a, "British|English|UK") ~ "British",
      is.na(q8_a) | q8_a == "" ~ "Other",
      TRUE ~ "Other"
    ),
    # Clean network size variable (q13)
    network_size = pmin(q13, 50, na.rm = TRUE), # Cap at 50 for visualization
    network_size = pmax(network_size, 1, na.rm = TRUE), # Minimum size 1
    wave_factor = factor(wave, levels = 1:5, labels = paste("Wave", 1:5))
  ) %>%
  # Identify seeds: either ridc == "seed" or zero indegree (not recruited by anyone)
  dplyr::mutate(
    is_seed = if("ridc" %in% names(.)) {
      tolower(ridc) == "seed" | recruiter.id == -1 | is.na(recruiter.id)
    } else {
      recruiter.id == -1 | is.na(recruiter.id)
    }
  )

# Create edge list for network graph
edges <- data_viz %>%
  dplyr::filter(!is_seed, !is.na(recruiter.id)) %>%
  dplyr::select(from = recruiter.id, to = id) %>%
  dplyr::filter(from %in% data_viz$id) # Ensure recruiter exists in dataset

# Calculate out-degree (number of people each node recruited)
out_degree <- edges %>%
  dplyr::count(from, name = "out_degree") %>%
  dplyr::rename(id = from) %>%
  dplyr::mutate(id = as.integer(id))

# Create nodes dataframe
nodes <- data_viz %>%
  dplyr::select(id, nationality_cluster, network_size, wave, is_seed) %>%
  dplyr::left_join(out_degree, by = "id") %>%
  dplyr::mutate(
    out_degree = ifelse(is.na(out_degree), 0, out_degree),
    # Size nodes by out-degree (number recruited)
    node_size = dplyr::case_when(
      is_seed ~ 6,  # Base size for seeds
      TRUE ~ 3      # Base size for recruits
    ) + out_degree * 1.5,  # Scale up by number of recruits
    node_alpha = ifelse(is_seed, 0.9, 0.7)
  )

# Create igraph object
if(nrow(edges) > 0) {
  g <- graph_from_data_frame(edges, directed = TRUE, vertices = nodes)
} else {
  # If no edges, create graph from vertices only
  g <- graph_from_data_frame(data.frame(from=character(0),
to=character(0)),
                             directed = TRUE, vertices = nodes)
}

# Set up colors for nationality clusters
n_clusters <- length(unique(nodes$nationality_cluster))
colors <- RColorBrewer::brewer.pal(min(n_clusters, 8), 
"Set2")[1:n_clusters]
names(colors) <- sort(unique(nodes$nationality_cluster))

# Create the network plot
set.seed(42) # For reproducible layout

p <- ggraph(g, layout = "fr") + 
  geom_edge_link(
    arrow = arrow(length = unit(0.1, "inches"), type = "closed"),
    alpha = 0.6,
    color = "gray50",
    width = 0.5
  ) +
  geom_node_point(
    aes(
      size = node_size,
      color = nationality_cluster,
      alpha = node_alpha,
      shape = is_seed
    )
  ) +
  scale_size_identity() +
  scale_color_manual(
    values = colors,
    name = "Nationality\nCluster"
  ) +
  scale_alpha_identity() +
  scale_shape_manual(
    values = c("TRUE" = 17, "FALSE" = 16), # Triangle for seeds, circle for recruits
    name = "Node Type",
    labels = c("TRUE" = "Seed", "FALSE" = "Recruit")
  ) +
  theme_graph() +
  theme(
    legend.position = "right",
    legend.box = "vertical",
    legend.margin = margin(t = 0, r = 0, b = 0, l = 10),
    plot.title = element_text(size = 14, hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5, color = "gray60"),
    text = element_text(family = ""),
    legend.text = element_text(family = ""),
    legend.title = element_text(family = "")
  ) +
  labs(
    title = "RDS Recruitment Network Structure",
    subtitle = paste("Sample size: n =", nrow(nodes),
                     "| Seeds:", sum(nodes$is_seed),
                     "| Recruitment chains:", nrow(edges))
  ) +
  guides(
    color = guide_legend(override.aes = list(size = 5)),
    shape = guide_legend(override.aes = list(size = 5))
  )

# Print the plot with error handling
tryCatch({
  print(p)
}, error = function(e) {

  # Simple fallback plot
  library(ggplot2)
  fallback_plot <- data_viz %>%
    ggplot(aes(x = nationality_cluster, fill = nationality_cluster)) +
    geom_bar() +
    labs(
      title = "Sample Distribution by Nationality Cluster",
      x = "Nationality Cluster",
      y = "Count"
    ) +
    theme_minimal() +
    theme(
      text = element_text(family = ""),
      legend.position = "none"
    )

  print(fallback_plot)
})
```

```{r}
#| label: tbl-sample-characteristics
#| tbl-cap: "RDS Sample Characteristics by Nationality Cluster and Recruitment Wave. Source: Authors' Own Work."
#| echo: false

# Load kableExtra for professional table formatting
library(kableExtra)

# Create sample characteristics table
sample_summary <- data_viz %>%
  dplyr::group_by(nationality_cluster) %>%
  dplyr::summarise(
    n = dplyr::n(),
    percentage = round(dplyr::n() / nrow(data_viz) * 100, 1),
    seeds = sum(is_seed),
    recruits = sum(!is_seed),
    mean_network_size = round(mean(q13, na.rm = TRUE), 1),
    median_network_size = round(median(q13, na.rm = TRUE), 1),
    .groups = 'drop'
  ) %>%
  dplyr::arrange(desc(n))

# Format table
sample_summary %>%
  kableExtra::kbl(
    col.names = c("Nationality", "N", "%", "Seeds", "Recruits", "Mean Degree", "Median Degree"),
    caption = "Sample Characteristics by Nationality Cluster",
    booktabs = TRUE,
    align = c("l", "r", "r", "r", "r", "r", "r")
  ) %>%
  kableExtra::kable_styling(
    latex_options = c("striped", "hold_position", "scale_down"),
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width = FALSE,
    position = "center",
    font_size = 9
  ) %>%
  kableExtra::footnote(
    general = "Degree refers to reported network size (Q13: number of domestic workers known).",
    general_title = "Note:",
    footnote_as_chunk = TRUE
  )
```

```{r}
#| label: tbl-wave-distribution
#| tbl-cap: "Distribution of Sample Across Recruitment Waves. Source: Authors' Own Work."
#| echo: false
#| eval: false

# Create wave distribution table
wave_summary <- data_viz %>%
  dplyr::group_by(wave) %>%
  dplyr::summarise(
    n = dplyr::n(),
    percentage = round(dplyr::n() / nrow(data_viz) * 100, 1),
    seeds = sum(is_seed),
    recruits = sum(!is_seed),
    .groups = 'drop'
  ) %>%
  dplyr::mutate(
    wave_label = paste("Wave", wave)
  ) %>%
  dplyr::select(wave_label, n, percentage, seeds, recruits)

# Add totals row
totals <- data.frame(
  wave_label = "Total",
  n = nrow(data_viz),
  percentage = 100.0,
  seeds = sum(data_viz$is_seed),
  recruits = sum(!data_viz$is_seed)
)

wave_summary <- rbind(wave_summary, totals)

# Format table
wave_summary %>%
  kableExtra::kbl(
    col.names = c("Recruitment Wave", "N", "%", "Seeds", "Recruits"),
    caption = "Recruitment Wave Distribution",
    booktabs = TRUE,
    align = c("l", "r", "r", "r", "r")
  ) %>%
  kableExtra::kable_styling(
    latex_options = c("striped", "hold_position", "scale_down"),
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width = FALSE,
    position = "center"
  ) %>%
  kableExtra::row_spec(nrow(wave_summary), bold = TRUE, hline_after = TRUE) %>%
  kableExtra::footnote(
    general = "Seeds are initial participants (recruiter.id = -1). Recruits are referred participants.",
    general_title = "Note:",
    footnote_as_chunk = TRUE
  )
```

### Indicators

creating comparable variables to bridge the Respondent-Driven Sampling (RDS) and Network Scale-Up Method (NSUM) estimations is a key methodological challenge the research team is actively working to solve.
The core issue is that the two methods rely on differently framed questions: • RDS estimation uses "egocentric" questions, which focus on the respondent's personal experiences (e.g., "Have you been forced to work?").
• NSUM estimation uses questions about the respondent's knowledge of others in their network (e.g., "How many domestic workers do you know who have experienced...").
The survey questions designed for these two purposes do not always match up directly, making a fair comparison between the estimates difficult.
The Strategy: Creating "Linking" Variables To overcome this, the team's strategy is to identify and group questions that cover the same underlying themes, even if they are worded differently for each method.
The goal is to aggregate some of the specific "egocentric" questions to make them comparable to the broader "how many do you know" NSUM questions.
Based on your sources, several sets of "linking" questions have been identified with varying degrees of confidence in their comparability: • Document Withholding (High Confidence): ◦ RDS Question: Q70 asks if the employer has withheld the respondent's travel and identity documents.
◦ NSUM Question: Q71 asks how many other domestic workers the respondent knows who do not have access to their own documents.
• Debt and Pay Issues (High Confidence): ◦ RDS Questions: This involves combining Q39 (having to pay off debt to someone who helped find work) and Q42 (has your pay ever been withheld?).
◦ NSUM Question: Q43 asks how many others the respondent knows who have experienced problems with debt or pay.
• Abuse and Threats (Medium Confidence): ◦ RDS Questions: This requires grouping Q45 (forced, deceived, or threatened into poor working conditions), Q47 (employer intimidation or threats), and Q48 (verbal abuse).
◦ NSUM Question: Q49 asks how many others the respondent knows who have experienced the use of threat or force.
• Excessive Hours (Lower Confidence): ◦ RDS Questions: Q61 (weekly rest does not last 24 hours) and Q62 (working excessive overtime) are combined.
◦ NSUM Question: Q64 asks about knowing others who work excessive overtime, lack breaks, or lack annual leave.
The comparison here is considered "flakier" because the RDS questions do not ask about annual leave, creating a partial mismatch.
• Access to Help (Lower Confidence): ◦ RDS Question: Q78 asks if the respondent knows who might help them (coded for "No" answers).
◦ NSUM Question: Q79 asks how many other domestic workers the respondent knows who do NOT know where to go for help.
By creating these comparable variables, even if just for one or two highly confident themes like debt bondage or document withholding, the team hopes to perform a fair comparison between the estimates derived from the two different methodologies.
This process is considered a crucial step to integrate the RDS and NSUM approaches and to produce more robust findings.

### Ethical Approval

The data collection that underpins the analysis presented in this paper was given favourable ethical approval by the lead author’s School Research Ethics Committee in January 2023.
All participants were informed about the aims of the study, provided informed consent, and were assured that participation was voluntary and confidential.

### Use of Artificial Intelligence in Research

Large Language Models (LLMs) were used for brainstorming the organisation of the paper and editing of text.
Code co-pilot (Claude Code) was used to test and debug R scripts employed in the statistical analysis.
No generative models were used to generate or simulate data.

## Estimation Methods

We analysed the survey sample using multiple estimation models in order to assess robustness and conduct sensitivity analyses (see Appendix XX).
The survey instrument contained both ego questions (which capture information about respondents and their personal network ties) and alter questions (which capture information about the people respondents know).
These two types of network data enable two fundamentally different estimation strategies: respondent-driven sampling (RDS) estimators and network scale-up methods (NSUM).
In addition, we developed and implemented a novel three-step bootstrap procedure to address uncertainty in NSUM estimates, which we describe in more detail below.

### RDS-Based Estimation

RDS estimators use ego-based information.
Each participant reported the number of other domestic workers they knew, and this degree information was used to adjust for the over-representation of highly connected individuals in the sample.
We implemented RDS-II and Gile’s successive sampling (SS) estimator, the latter of which accounts for finite population effects and improves performance when the sample fraction is relatively large (Gile, 2011; Gile and Handcock, 2010).
These estimators were used to generate prevalence estimates for binary indicators of exploitation.

For continuous traits, such as the exploitation risk index, we applied model-assisted inference approaches (@gile15-network, Gile, 2011; Gile, Beaudry, and Handcock, 2018).
These approaches combine design-based adjustments with regression models that incorporate auxiliary covariates, producing valid estimates of sample means and distributions of continuous outcomes under the RDS design.

### Estimation Strategy

Given that our data were collected using a respondent-driven sampling (RDS) design, the choice of estimator is critical.
We considered several well-established RDS estimators, each with distinct assumptions and applicability.

First, the RDS-I estimator @salg04-samplin provides an early design-based approach.
However, it performs poorly in small samples, is highly sensitive to seed dependence, and requires strong assumptions about equilibrium.
Since our sample comprises fewer than 100 respondents recruited from multiple seeds, we regard RDS-I primarily as a historical benchmark rather than a viable option for inference.

Second, the Volz–Heckathorn (VH) estimator @volz08-probabi offers a probability-based refinement of RDS-I.
It is more robust but assumes a large population relative to the sample size and does not adjust for finite-population effects.
Although our diagnostic checks indicated approximate equilibrium across key demographics, the VH estimator is best used here as a robustness check rather than the primary estimator.

Third, the Successive Sampling (RDS-SS) estimator (also called RDS-II) @gile11-improve accounts for finite population effects, adjusting for the non-negligible sampling fraction that arises when the target population is not extremely large relative to the sample.
This property makes RDS-SS particularly appropriate for our study of migrant domestic workers, and we therefore use it as our primary estimator for binary outcomes (e.g., presence or absence of exploitation).

Fourth, to estimate continuous outcomes such as our exploitation risk index, we employ the Model-Assisted (MA-RDS) estimator @gile15-network.
This approach integrates regression modelling with RDS weights, thereby extending inference beyond binary outcomes and improving efficiency by leveraging auxiliary covariates.


In summary, we rely primarily on RDS-SS for binary outcomes and MA-RDS for continuous and binary indicators, with VH used for robustness checks.
This combined strategy balances methodological rigor with the substantive goals of our study.

We use model-assisted RDS estimators (@gile15-network) because they are design-based yet leverage a working ERGM (with degree and homophily terms) to approximate inclusion probabilities conditional on our observed seeds.
This approach directly addresses seed bias and homophily that conventional RDS estimators cannot correct, accommodates finite-population effects through successive-sampling logic, and supports valid estimation of both binary and continuous outcomes.
By conditioning on the actual seed composition and subgroup structure in our data, the method reduces bias, improves efficiency, and provides design-compatible bootstrap uncertainty, making it particularly well-suited to our small, heterogeneous sample of domestic workers.”

### Network Scale-Up Methods (NSUM)

NSUM relies on alter-based information.
Rather than depending on respondents’ own position in the referral network and their reported degree, NSUM uses information about alters—other people in respondents’ networks.
Participants reported on the number and characteristics of people they knew who met specific exploitation criteria.
These reports were aggregated to estimate prevalence in the wider population of domestic workers.

The key methodological distinction between RDS and NSUM lies in how the social network is used.
RDS leverages ego-level network size and recruitment paths to adjust for biases in the referral process.
NSUM treats respondents as informants about a larger social universe, using alter data to infer prevalence.
RDS depends on accurate self-reporting of degree and on the properties of recruitment chains, while NSUM depends on the accuracy of respondents’ knowledge about others and the representativeness of their social networks

#### How RDS and NSUM Use Social Network Information

Respondent-driven sampling (RDS) and network scale-up methods (NSUM) both rely on social network structures, but they exploit different aspects of those structures for inference.

RDS uses ego-based information. Each participant reports the size of their personal network of eligible individuals, and these degree reports are combined with the wave at which respondents were recruited to adjust for unequal inclusion probabilities. The underlying logic is that individuals with larger networks are more likely to be recruited earlier and more often, creating a bias toward highly connected respondents. RDS estimators, including Gile’s successive sampling estimator, explicitly correct for this bias by weighting observations according to network degree and recruitment path. For continuous traits, such as our risk index, RDS model-assisted estimators incorporate auxiliary covariates into this weighting process to further reduce bias.

In contrast, NSUM uses alter-based information. Rather than focusing on the ego’s probability of inclusion, NSUM treats respondents as informants about the wider hidden population. Respondents are asked how many people they know with a given trait (for example, “How many domestic workers do you know who have experienced exploitation?”). These responses are then scaled up, using assumptions about network size and visibility, to infer prevalence in the broader population. This method does not depend on recruitment chains but instead on the accuracy of respondents’ knowledge about others in their social circles.

The practical difference is therefore twofold. RDS estimates are anchored in “who recruited whom” and “how many do you know,” while NSUM estimates are anchored in “how many of your alters fit this category.” RDS leverages inclusion probabilities tied to ego network size; NSUM leverages alter reports to extend beyond the sample. Applying both methods to the same dataset allows for triangulation across two fundamentally different inferential logics.

### Bootstrap Procedure for NSUM

To appropriately characterise uncertainty in NSUM estimates, we developed a novel three-step bootstrap procedure.
This approach resamples respondents, their reported alters, and the exploitation classifications simultaneously, thereby capturing uncertainty at each stage of the inference process.
This procedure provides more realistic confidence intervals than those generated by conventional variance estimators, particularly for small samples such as ours.
Details of the bootstrap implementation and diagnostic checks are provided in Appendix @app-3step.

### Comparative Rationale

Respondent-driven sampling (RDS) and network scale-up methods (NSUM) both rely on social network structures, but they exploit different aspects of those structures for inference.

RDS uses ego-based information.
Each participant reports the size of their personal network of eligible individuals, and these degree reports are combined with the wave at which respondents were recruited to adjust for unequal inclusion probabilities.
The underlying logic is that individuals with larger networks are more likely to be recruited earlier and more often, creating a bias toward highly connected respondents.
RDS estimators, including Gile’s successive sampling estimator, explicitly correct for this bias by weighting observations according to network degree and recruitment path.
For continuous traits, such as our risk index, RDS model-assisted estimators incorporate auxiliary covariates into this weighting process to further reduce bias.

In contrast, NSUM uses alter-based information.
Rather than focusing on the ego’s probability of inclusion, NSUM treats respondents as informants about the wider hidden population.
Respondents are asked how many people they know with a given trait (for example, “How many domestic workers do you know who have experienced exploitation?”).
These responses are then scaled up, using assumptions about network size and visibility, to infer prevalence in the broader population.
This method does not depend on recruitment chains but instead on the accuracy of respondents’ knowledge about others in their social networks.

The practical difference is therefore twofold.
RDS estimates are anchored in “who recruited whom” and “how many do you know,” while NSUM estimates are anchored in “how many of your alters fit this category.” RDS leverages inclusion probabilities tied to ego network size; NSUM leverages alter reports to extend beyond the sample.
Applying both methods to the same dataset allows for triangulation across two fundamentally different inferential logics.

Applying both RDS and NSUM to the same survey allows triangulation across two fundamentally different inferential paradigms.
For continuous outcomes, such as the exploitation risk index, only model-assisted RDS estimators are appropriate.
For binary outcomes, both RDS and NSUM can be applied, enabling direct comparison of results.
This dual approach strengthens the empirical credibility of our findings, highlights the conceptual value of considering exploitation both as a binary threshold and as a continuum, and demonstrates the methodological trade-offs involved in studying hidden populations.

## Results

### Model-Assisted Estimates of the Risk Index (Continuous Conceptualisation)

One of the central contributions of this study is the introduction of a continuous risk index to measure degrees of exposure to labour exploitation.
The index was constructed from multiple indicators aligned with the International Labour Organization’s forced labour framework, weighted inductively and refined through expert consultation.
Rather than treating exploitation as a dichotomy, the risk index conceptualises all domestic workers as facing some degree of potential exploitation, albeit with significant variation in intensity.

Because continuous traits cannot be estimated directly with conventional RDS estimators or NSUM, we employed model-assisted inference methods.
These methods adjust for the non-random structure of RDS recruitment while permitting reliable estimation of means and distributions of continuous outcomes (Gile, 2011; Gile and Handcock, 2010; Gile, Beaudry, and Handcock, 2018).

```{r}
#| label: fig-ma-risk-estimates
#| fig-cap: "Model-Assisted Estimates of Composite Risk Index: Distribution comparison between observed sample data and population-adjusted estimates. The left panel shows the empirical distribution of risk scores in the RDS sample, while the right panel presents the model-assisted population proportion estimates for specific risk categories with uncertainty bounds (the light band shows confidence intervals around the proportion estimates). Source: Authors' Own Work."
#| fig-width: 12     # REDUCE from 14
#| fig-height: 5     # REDUCE from 6
#| out-width: "100%" # ADD this
#| echo: false
#| warning: false
#| message: false

# Load required packages
suppressPackageStartupMessages({
  library(dplyr)
  library(ggplot2)
  library(patchwork)
  library(scales)
  library(here)
})

# Load data and MA results
load(here("data", "processed", "prepared_data.RData"))
load(here("output", "ma_result_composite_risk.RData"))

# Extract MA estimates - the estimate object contains the population-adjusted distribution
ma_estimates <- ma_result$estimate$estimate
ma_intervals <- ma_result$estimate$interval[1:length(ma_estimates)]

# Create data for plots
risk_values <- as.numeric(names(ma_estimates))
estimated_proportions <- as.numeric(ma_estimates)

# Calculate sample statistics
sample_mean <- mean(prepared_data$composite_risk, na.rm = TRUE)
sample_sd <- sd(prepared_data$composite_risk, na.rm = TRUE)

# Population-weighted mean and SD from MA estimates
pop_mean <- sum(risk_values * estimated_proportions)
pop_variance <- sum((risk_values - pop_mean)^2 * estimated_proportions)
pop_sd <- sqrt(pop_variance)

# Create sample data plot
p1 <- prepared_data %>%
  dplyr::filter(!is.na(composite_risk)) %>%
  ggplot(aes(x = composite_risk)) +
  geom_histogram(aes(y = after_stat(density)),
                 bins = 20, fill = "steelblue", alpha = 0.7, color = "white") +
  geom_density(color = "darkblue", linewidth = 1.2) +
  geom_vline(xintercept = sample_mean, color = "red", linetype = "dashed", linewidth = 1) +
  labs(
    title = "A. Observed Sample Distribution",
    subtitle = paste("n =", sum(!is.na(prepared_data$composite_risk))),
    x = "Composite Risk Index",
    y = "Density"
  ) +
  annotate("text", x = sample_mean + 0.02, y = Inf,
           label = paste("Sample Mean =", round(sample_mean, 3)),
           vjust = 2, hjust = 0, color = "red", size = 3.5) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 12, face = "bold"),
    plot.subtitle = element_text(size = 10),
    axis.title = element_text(size = 10),
    panel.grid.minor = element_blank()
  )

# Create MA estimates plot with uncertainty
# For composite risk, construct CI for each category proportion using SE
se <- sqrt(ma_result$varest)
ma_data <- data.frame(
  risk_score = risk_values,
  estimate = estimated_proportions,
  lower_ci = pmax(0, estimated_proportions - 1.96 * se),
  upper_ci = pmin(1, estimated_proportions + 1.96 * se)
)

p2 <- ma_data %>%
  ggplot(aes(x = risk_score)) +
  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci),
              fill = "orange", alpha = 0.3) +
  geom_line(aes(y = estimate), color = "darkorange", linewidth = 1.5) +
  geom_point(aes(y = estimate), color = "darkorange", size = 2) +
  geom_vline(xintercept = pop_mean, color = "red", linetype = "dashed", linewidth = 1) +
  labs(
    title = "B. Model-Assisted Population Estimates",
    subtitle = "Population-adjusted with uncertainty bands",
    x = "Composite Risk Index",
    y = "Estimated Population Proportion"
  ) +
  annotate("text", x = pop_mean + 0.02, y = Inf,
           label = paste("Pop. Mean =", round(pop_mean, 3)),
           vjust = 2, hjust = 0, color = "red", size = 3.5) +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 12, face = "bold"),
    plot.subtitle = element_text(size = 10),
    axis.title = element_text(size = 10),
    panel.grid.minor = element_blank()
  )

# Combine plots
combined_plot <- p1 + p2 +
  plot_layout(ncol = 2) +
  plot_annotation(
    title = "Composite Risk Index: Sample vs. Population-Adjusted Estimates",
    theme = theme(plot.title = element_text(size = 14, face = "bold", hjust = 0.5))
  )

print(combined_plot)

# Summary statistics are now integrated into the inline text below
```



@fig-ma-risk-estimates presents the comparison between the observed sample distribution and the model-assisted population estimates, demonstrating how the bias correction affects our understanding of exploitation risk in the broader domestic worker population.  The population-weighted average risk is $0.0124$ This represents the Model-Assisted estimate of mean exploitation risk in the population, adjusted for RDS sampling bias. It is a design-based estimate that corrects for the non-random recruitment process in RDS.
The population-adjusted distribution shows less concentration in the lower risk values compared to the raw sample.  The MA estimate suggests that  $~7.2\%$ of DWs in the UK have moderate risk (0.1725)
This pattern reinforces the conceptual claim that exploitation is best understood as a continuum rather than a simple binary condition.

### Binary Exploitation Indicators (Exploited or Not Exploited)

To complement the continuous measure, we also operationalised exploitation as a binary outcome.
Respondents were classified as exploited if they met threshold indicators consistent with ILO definitions.
This allows estimation using both respondent-driven sampling estimators, which rely on ego-based network data, and network scale-up methods, which rely on alter-based information.

#### Model-Assisted (MA) Estimates

```{r}
#| label: tbl-ma-binary-indicators
#| tbl-cap: "Model-Assisted Estimates of Binary Exploitation Indicators: Population prevalence estimates adjusted for RDS sampling bias. Values represent the estimated proportion of domestic workers experiencing each form of exploitation. Source: Authors' Own Work."
#| echo: false
#| warning: false
#| message: false

# Load required packages
suppressPackageStartupMessages({
  library(dplyr)
  library(kableExtra)
  library(here)
})

# Define indicator files and labels
ma_files <- c(
  "document_withholding_rds" = "Document Withholding",
  "pay_issues_rds" = "Pay-Related Issues",
  "threats_abuse_rds" = "Threats/Abuse",
  "excessive_hours_rds" = "Excessive Hours",
  "access_to_help_rds" = "Limited Access to Help",
  "whether_exploitation" = "Any Exploitation"
)

# Function to extract MA sensitivity estimates
# Uses posterior distribution from Bayesian Model Assisted 
extract_ma_estimate <- function(file_path) {
  if (file.exists(file_path)) {
    load(file_path)
    if (exists("ma_result") && !is.null(ma_result$estimate)) {
      # Extract from posterior distribution intervals
      interval <- ma_result$estimate$interval
      if (length(interval) >= 6) {
        # Point estimate from interval[2] (posterior mean for indicator=1)
        prevalence <- interval[2]
        # 95% Credible Interval from interval[4] to interval[6]
        ci_lower <- interval[4]
        ci_upper <- interval[6]

        return(list(
          prevalence = as.numeric(prevalence),
          ci_lower = as.numeric(ci_lower),
          ci_upper = as.numeric(ci_upper)
        ))
      }
    }
  }
  return(list(prevalence = NA, ci_lower = NA, ci_upper = NA))
}

# Extract all MA sensitivity results (population=980000, seed.selection='sample')
ma_results <- data.frame(
  indicator = names(ma_files),
  label = as.character(ma_files),
  stringsAsFactors = FALSE
)

for (i in 1:nrow(ma_results)) {
  file_path <- here("output", paste0("ma_sensitivity_", ma_results$indicator[i],
                                     "_980000_sample.RData"))
  result <- extract_ma_estimate(file_path)
  ma_results$prevalence[i] <- result$prevalence
  ma_results$ci_lower[i] <- result$ci_lower
  ma_results$ci_upper[i] <- result$ci_upper
}

# Format results table
ma_results_formatted <- ma_results %>%
  dplyr::mutate(
    prevalence_pct = round(prevalence * 100, 1),
    ci_lower_pct = round(ci_lower * 100, 1),
    ci_upper_pct = round(ci_upper * 100, 1),
    estimate_ci = ifelse(
      !is.na(prevalence_pct),
      sprintf("%.1f%% (%.1f-%.1f%%)", prevalence_pct, ci_lower_pct, ci_upper_pct),
      "Not available"
    )
  ) %>%
  dplyr::select(label, estimate_ci) %>%
  dplyr::arrange(desc(ma_results$prevalence))

# Create professional table
ma_results_formatted %>%
  kableExtra::kbl(
    col.names = c("Exploitation Indicator", "Population Prevalence (95% CrI)"),
    caption = "Model-Assisted Estimates of Binary Exploitation Indicators",
    booktabs = TRUE,
    align = c("l", "r")
  ) %>%
  kableExtra::kable_styling(
    latex_options = c("striped", "hold_position", "scale_down"),
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width = FALSE,
    position = "center"
  ) %>%
  kableExtra::footnote(
    general = "Estimates adjusted for RDS sampling bias using Bayesian Model Assissted Inference of Gile & Handcock (2015) (N=980,000, sample seed selection). Credible intervals from posterior distribution.",
    general_title = "Note:",
    footnote_as_chunk = TRUE
  )
```

```{r}
#| label: fig-ma-binary-forest
#| fig-cap: "Forest Plot of Model-Assisted Binary Exploitation Estimates: Population prevalence estimates with 95% credible intervals for each exploitation indicator, ordered by prevalence magnitude. Error bars represent posterior uncertainty from Bayesian SS-PSE (N=980,000, sample seed selection). Source: Authors' Own Work."
#| fig-width: 8      # REDUCE from 10
#| fig-height: 5     # REDUCE from 6
#| out-width: "95%"  # ADD this
#| echo: false
#| warning: false
#| message: false

library(ggplot2)

# Create forest plot data
# Point estimate from interval[2], 95% CrI from interval[4] to interval[6]
# CrIs are from the posterior distribution (Bayesian MA)
forest_data <- ma_results %>%
  dplyr::filter(!is.na(prevalence)) %>%
  dplyr::mutate(
    prevalence_pct = prevalence * 100,
    ci_lower_pct = ci_lower * 100,
    ci_upper_pct = ci_upper * 100,
    # Order from lowest (bottom) to highest (top) prevalence
    label_clean = factor(label, levels = label[order(prevalence)])
  )

# Create forest plot
forest_plot <- forest_data %>%
  ggplot(aes(x = prevalence_pct, y = label_clean)) +
  geom_errorbarh(aes(xmin = ci_lower_pct, xmax = ci_upper_pct),
                 height = 0.2, color = "steelblue", linewidth = 1) +
  geom_point(size = 3, color = "darkblue") +
  geom_text(aes(label = sprintf("%.1f%%", prevalence_pct)),
            vjust = -0.8, size = 3.5, color = "darkblue") +
  labs(
    title = "Model-Assisted Estimates of Exploitation Prevalence",
    subtitle = "Population estimates adjusted for RDS sampling bias",
    x = "Estimated Prevalence (%)",
    y = "Exploitation Indicator"
  ) +
  scale_x_continuous(
    labels = scales::percent_format(scale = 1),
    limits = c(0, max(forest_data$ci_upper_pct, na.rm = T) * 1.1)
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 12, face = "bold"),
    plot.subtitle = element_text(size = 10),
    axis.title = element_text(size = 10),
    axis.text.y = element_text(size = 9),
    panel.grid.minor = element_blank(),
    panel.grid.major.y = element_blank()
  )

print(forest_plot)

# Summary information integrated into the narrative text
```


#### RDS Estimates

```{r}
#| label: tbl-rds-binary-indicators
#| tbl-cap: "RDS Estimates of Binary Exploitation Indicators: Comparison of RDS-I and RDS-SS estimators with neighborhood bootstrap confidence intervals (N=980,000). Source: Authors' Own Work."
#| echo: false
#| warning: false
#| message: false

# Load RDS frequentist estimates
if (file.exists(here("output", "frequentist_estimators_results.RData"))) {
  load(here("output", "frequentist_estimators_results.RData"))

  if (exists("frequentist_df")) {
    # Filter for 980K population and RDS-I and RDS-SS methods
    rds_comparison <- frequentist_df %>%
      dplyr::filter(
        pop_size == 980000,
        method %in% c("RDS_I", "RDS_SS")
      ) %>%
      dplyr::select(indicator_clean, method_clean, estimate_with_ci) %>%
      tidyr::pivot_wider(
        names_from = method_clean,
        values_from = estimate_with_ci
      ) %>%
      dplyr::rename(`Exploitation Indicator` = indicator_clean)

    # Create table
    rds_comparison %>%
      kableExtra::kbl(
        booktabs = TRUE,
        align = c("l", "r", "r")
      ) %>%
      kableExtra::kable_styling(
        latex_options = c("striped", "hold_position", "scale_down"),
        bootstrap_options = c("striped", "hover", "condensed"),
        full_width = FALSE,
        position = "center",
        font_size = 9
      ) %>%
      kableExtra::footnote(
        general = "RDS-I: Salganik-Heckathorn estimator. RDS-SS: Gile's Successive Sampling estimator. Confidence intervals from neighborhood bootstrap (n=1000). Population size: 980,000 domestic workers.",
        general_title = "Note:",
        footnote_as_chunk = TRUE
      )
  } else {
    cat("frequentist_df object not found.\n")
  }
} else {
  cat("frequentist_estimators_results.RData file not found.\n")
}
```


```{r}
#| label: fig-rds-forest-plot
#| fig-cap: "Forest Plot of RDS Estimates: Comparison of RDS-I and RDS-SS prevalence estimates for binary exploitation indicators (N=980,000). Error bars represent 95% bootstrap confidence intervals. Source: Authors' Own Work."
#| fig-width: 9
#| fig-height: 6
#| out-width: "95%"
#| echo: false
#| warning: false

library(ggplot2)

# Create forest plot for RDS estimates
if (exists("frequentist_df")) {
  rds_forest_data <- frequentist_df %>%
    dplyr::filter(
      pop_size == 980000,
      method %in% c("RDS_I", "RDS_SS")
    )

  # Order indicators by average prevalence (lowest to highest)
  indicator_order <- rds_forest_data %>%
    dplyr::group_by(indicator_clean) %>%
    dplyr::summarise(avg_est = mean(estimate_pct)) %>%
    dplyr::arrange(avg_est) %>%
    dplyr::pull(indicator_clean)

  rds_forest_data <- rds_forest_data %>%
    dplyr::mutate(
      indicator_ordered = factor(indicator_clean, levels = indicator_order)
    )

  if (nrow(rds_forest_data) > 0) {
    forest_plot <- ggplot(rds_forest_data,
                          aes(x = estimate_pct, y = indicator_ordered,
                              color = method_clean, shape = method_clean)) +
      geom_errorbarh(aes(xmin = ci_lower_pct, xmax = ci_upper_pct),
                     height = 0.2, position = position_dodge(width = 0.5),
                     linewidth = 1) +
      geom_point(size = 4, position = position_dodge(width = 0.5)) +
      geom_text(aes(label = sprintf("%.1f%%", estimate_pct)),
                vjust = -1.0, size = 3,
                position = position_dodge(width = 0.5),
                show.legend = FALSE) +
      scale_color_brewer(palette = "Set1", name = "RDS Method") +
      scale_shape_manual(values = c(16, 17), name = "RDS Method") +
      labs(
        title = "RDS Prevalence Estimates by Method",
        subtitle = "Population size: 980,000 domestic workers",
        x = "Estimated Prevalence (%)",
        y = "Exploitation Indicator"
      ) +
      theme_minimal() +
      theme(
        plot.title = element_text(size = 12, face = "bold"),
        plot.subtitle = element_text(size = 10),
        axis.text.y = element_text(size = 10),
        legend.position = "bottom",
        panel.grid.major.y = element_blank()
      )

    print(forest_plot)
  } else {
    cat("No RDS data available for forest plot.\n")
  }
} else {
  cat("frequentist_df not loaded.\n")
}
```



#### NSUM Estimates

Using the Modified Basic Scale-Up (MBSU) estimator with Sequential Sampling weights and an estimated UK domestic worker population of 980,000, we find substantial variation in prevalence estimates depending on the adjustment factors applied (@tbl-nsum-main).

The unadjusted MBSU estimates (baseline scenario with no adjustment for visibility or reporting barriers, δ=1.0, τ=1.0) suggest that document withholding affects approximately 8,120 workers (0.83%, 95% CI: 0.23%-2.39%). Pay-related issues affect 21,560 workers (2.20%, 95% CI: 1.45%-4.35%), while threats and abuse affect 20,141 workers (2.06%, 95% CI: 1.42%-4.48%). Excessive working hours affect 22,375 workers (2.28%, 95% CI: 1.41%-4.21%), and 15,212 workers report lacking access to help (1.55%, 95% CI: 0.51%-3.73%).

Applying moderate adjustments for reporting and visibility biases (δ=0.9, τ=0.85) yields estimates of 10,615 workers experiencing document withholding (1.08%, 95% CI: 0.30%-3.13%), 28,182 with pay issues (2.88%, 95% CI: 1.90%-5.68%), 26,328 experiencing threats/abuse (2.69%, 95% CI: 1.86%-5.86%), 29,248 with excessive hours (2.98%, 95% CI: 1.84%-5.51%), and 19,885 lacking access to help (2.03%, 95% CI: 0.67%-4.88%).

The most conservative adjustments (δ=0.8, τ=0.7), accounting for greater underreporting and visibility barriers, produce substantially higher estimates: 14,500 workers with document withholding (1.48%, 95% CI: 0.40%-4.27%), 38,499 with pay issues (3.93%, 95% CI: 2.60%-7.77%), 35,966 experiencing threats/abuse (3.67%, 95% CI: 2.53%-8.00%), 39,955 with excessive hours (4.08%, 95% CI: 2.52%-7.53%), and 27,165 lacking access to help (2.77%, 95% CI: 0.91%-6.67%).

These estimates represent prevalence rates ranging from 0.83% to 4.08% across all indicators, with confidence intervals reflecting substantial uncertainty inherent in network-based estimation methods. The conservative adjustments yield estimates approximately 1.8 times higher than unadjusted estimates, while moderate adjustments produce intermediate values approximately 1.3 times higher than baseline.

```{r}
#| label: tbl-nsum-main
#| tbl-cap: "NSUM Prevalence Estimates for Labor Exploitation Indicators: Estimates using Modified Basic Scale-Up (MBSU) method with Sequential Sampling weights and population size of 980,000 domestic workers. Adjustment factors: δ (transmission/barrier effect) and τ (recall effect) control for visibility and reporting biases. Bootstrap confidence intervals based on neighborhood resampling (B=1000). Source: Authors' Own Work."
#| echo: false
#| warning: false
#| message: false

library(tidyverse)
library(kableExtra)

# Load comprehensive NSUM results
nsum_file <- here("output", "tables", "Table6_NSUM_main_results.csv")
if (file.exists(nsum_file)) {
  nsum_main <- read_csv(nsum_file, show_col_types = FALSE)

  # Format the table
  nsum_main %>%
    kbl(
      col.names = c("Adjustment Method", "Outcome", "Point Estimate",
                    "95% CI Lower", "95% CI Upper", "Prevalence (%)"),
      caption = "NSUM Prevalence Estimates for Labor Exploitation Indicators",
      booktabs = TRUE,
      align = c("l", "l", "r", "r", "r", "l"),
      format.args = list(big.mark = ",")
    ) %>%
    kable_styling(
      latex_options = c("striped", "hold_position", "scale_down"),
      bootstrap_options = c("striped", "hover", "condensed"),
      full_width = FALSE,
      position = "center",
      font_size = 9
    ) %>%
    column_spec(1, width = "3cm") %>%
    column_spec(2, width = "3cm") %>%
    column_spec(6, width = "3cm") %>%
    pack_rows("No Adjustment (δ=1.0, τ=1.0)", 1, 5) %>%
    pack_rows("Conservative (δ=0.8, τ=0.7)", 6, 10) %>%
    pack_rows("Moderate (δ=0.9, τ=0.85)", 11, 15) %>%
    footnote(
      general = "MBSU = Modified Basic Scale-Up method; δ = transmission/barrier effect (proportion of cases visible to network); τ = recall effect (accuracy of reporting); Bootstrap method: neighborhood resampling with 1000 iterations; Population base: 980,000 UK domestic workers.",
      general_title = "Note:",
      footnote_as_chunk = TRUE
    )
} else {
  cat("NSUM results file not found. Please run R/analysis/NSUM/extract_main_results.R\n")
}
```

### Comparative Interpretation

Table 1 summarises prevalence estimates across both methods, highlighting points of convergence and divergence.
While absolute values differ slightly across RDS and NSUM (reflecting differences in ego- versus alter-based assumptions), the overall pattern is remarkably stable.

@fig-method-comparison demonstrates the comparison between frequentist RDS estimators (RDS-I, RDS-II, RDS-SS) and Bayesian model-assisted methods across all exploitation indicators.
The horizontal spacing of estimates allows clear visual comparison of point estimates and uncertainty intervals, with RDS methods showing bootstrap confidence intervals and Bayesian methods showing credible intervals from MCMC estimation.
Both approaches identify similar patterns of exploitation prevalence, with excessive hours showing the highest prevalence across all methods, followed by threats/abuse and pay-related issues.



```{r}
#| label: fig-method-comparison
#| fig-cap: "Method Comparison: frequentists RDS vs Bayesian RDS Estimators. Point estimates and uncertainty intervals for prevalence of exploitation indicators across different estimation methods. RDS methods show 95% confidence intervals (bootstrap); Bayesian methods show 95% credible intervals (MCMC). Baseline population assumption: 980,000 domestic workers. Source: Authors' own work."
#| fig-width: 10     # REDUCE from 12
#| fig-height: 7     # REDUCE from 8
#| out-width: "100%" # ADD this
#| echo: false

knitr::include_graphics(here::here("output", "figures", "method_comparison.png"))
```

On the Role of Visibility in Explaining Differences Between NSUM and RDS Estimates
----------------------------------------------------------------------------------

Substantial discrepancies between hidden population prevalence estimates derived from Respondent-Driven Sampling (RDS) and the Network Scale-Up Method (NSUM) are widely observed in empirical research and simulation studies. In the present case, for example, egocentric RDS-based estimates (e.g., using Gile’s Successive Sampling estimator) suggest that 34% to 84% of respondents personally experienced indicators of exploitation. In contrast, the corresponding NSUM estimates suggest that only 2.9% to 5.1% of the general domestic worker population experiences these same harms. This stark divergence—often approaching an order of magnitude—warrants a careful methodological explanation.

Among the various sources of error affecting NSUM, the most important and widely documented is visibility bias, also referred to in some literature as transmission bias. Visibility refers to the extent to which members of a hidden population are known to belong to that population by members of the general population. In the context of NSUM, visibility determines whether a respondent can accurately report having connections to members of the hidden group. If visibility is low—because of stigma, secrecy, or lack of awareness—respondents will systematically underreport these ties. This causes a downward bias in the numerator of the NSUM estimator, thereby underestimating the size of the hidden population.

As Feehan and Salganik put it:

> “Transmission error occurs when respondents do not know or are unwilling to report the true group memberships of people they know” [@feeh16-gener, p. 155].

This issue has been recognized since the earliest implementations of NSUM. Bernard et al. describe it as a failure of the transmission condition—the assumption that a respondent will be aware of, and willing to disclose, the group membership of their contacts [@bern10-estima]. More recently, Maltiel et al. have addressed visibility bias using model-based (Bayesian) approaches, which estimate and correct for differential visibility between groups [@malt15-estima].

In contrast, RDS estimators such as the Volz–Heckathorn (RDS-II) and especially the Successive Sampling (SS) estimator rely on direct self-reporting of hidden group membership. That is, RDS respondents are asked whether they themselves belong to the group or exhibit a trait of interest. This egocentric measurement bypasses the visibility problem entirely. While RDS relies on its own set of assumptions—such as the random recruitment assumption, accurate self-reported degree, and a sufficiently connected social network—visibility is not among its main sources of bias.

Thus, while both NSUM and RDS are used to estimate the size or prevalence of hidden populations, they are subject to fundamentally different sources of error. In NSUM, low visibility leads to systematic underreporting, which can result in severe underestimation unless appropriately adjusted. Adjustments such as those proposed by Feehan and Salganik—including multiplicative correction factors for visibility ($\tau$ τ), degree ratio ($\delta$ δ), and barrier effects ($\rho$ ρ)—can mitigate these biases, but require additional data or assumptions [@feeh16-gener].

In your setting, where RDS estimates suggest that over 50% of respondents have experienced exploitation, but NSUM estimates suggest only 3–5% of the domestic worker population does so, visibility bias is almost certainly the dominant factor explaining the discrepancy. This is especially true in contexts involving exploitation, abuse, or trafficking—where group membership is often concealed both by victims and by observers. Respondents in the frame population may simply be unaware that their contacts are experiencing exploitation, leading to substantial underreporting.


Hense, visibility bias is a major and well-understood limitation of NSUM, and likely the principal reason why your NSUM estimates are substantially lower than those derived from RDS. The use of RDS-based estimators, particularly those that adjust for sample design such as Gile’s SS estimator, provides direct measurement of traits among the hidden population and avoids the visibility problem. Therefore, RDS estimates are often more accurate in estimating prevalence within the hidden population, whereas NSUM estimates are typically biased downward unless adjusted for visibility and related biases.



### Robustness Checks

A series of robustness checks were performed to assess the stability of the findings.
@fig-forest-plot presents a comprehensive forest plot comparing all prevalence estimates across indicators and methods, demonstrating remarkable consistency across different analytical approaches.
Bootstrap resampling confirmed that the RDS and NSUM estimates remained stable across repeated draws.
Sensitivity analyses excluding suspicious datapoints did not materially alter subgroup rankings.
Analyses restricted to single subgroups confirmed that the elevated prevalence among Latinx workers was not an artifact of recruitment dynamics.

The forest plot visualization clearly shows that traditional RDS estimators (RDS-I and RDS-SS) produced results consistent with the model-assisted and Bayesian estimates, albeit with wider confidence intervals in some cases.
The pattern of estimates is remarkably stable across methods, with excessive hours consistently showing the highest prevalence, followed by threats/abuse and pay-related issues, while document withholding shows more moderate prevalence levels.
This cross-method validation strengthens confidence in our findings and demonstrates the robustness of the dual estimation approach.
Full technical details are reported in Appendices B and C.

```{r}
#| label: fig-parameter-comparison
#| fig-cap: "Bayesian Parameter Sensitivity Analysis. Comparison of prevalence estimates using enhanced vs standard MCMC parameters for Bayesian model-assisted estimation. Enhanced parameters use longer burn-in periods and more iterations, particularly important for numeric and ordinal variables like composite risk scores. Error bars represent 95% Bayesian credible intervals. Source: Authors' own work."
#| fig-width: 9      # REDUCE from 10
#| fig-height: 5     # REDUCE from 6
#| out-width: "95%"  # ADD this
#| echo: false

knitr::include_graphics(here::here("output", "figures", "parameter_comparison.png"))
```

```{r}
#| label: fig-forest-plot
#| fig-cap: "Forest Plot of Exploitation Prevalence Estimates. Comprehensive comparison of prevalence estimates across all indicators and estimation methods, displayed as a forest plot with 95% confidence/credible intervals. Each row represents a different exploitation indicator, with points showing method-specific estimates and horizontal lines indicating uncertainty bounds. Demonstrates consistency of findings across different analytical approaches. Source: Authors' own work."
#| fig-width: 10     # REDUCE from 12
#| fig-height: 8     # REDUCE from 10
#| out-width: "100%" # ADD this
#| echo: false
#| eval: false

knitr::include_graphics(here::here("output", "figures", "model_comparison_forest_plot.png"))
```

## Discussion

### Implications for Policy

The UK Government has proved reluctant to respond to calls to remove the restrictive, tied, visa conditions currently in force for those migrant workers working in the UK on the Overseas Domestic Workers visa (@gower_calls_2016).
Maintaining these restrictive conditions prevents the ratification in the UK of C189, the International Convention for Domestic Workers (@ILO11-indicators).
If the estimates resulting from our study are correct, these visa conditions place migrant domestic workers at significant risk of serious forms of labour exploitation including, in its most severe form, exploitation that exhibits the characteristics of forced labour—legally considered a form of modern slavery.

To reduce the vulnerability of transnational domestic workers to this—and other—forms of labour exploitation, we urge policy-makers to reconsider these discriminatory visa conditions and offer the same freedoms to domestic workers that are enjoyed by other groups of workers under UK law.

In addition, given the vulnerabilities experienced by workers due to the private nature of the workplace, we would urge the UK government to consider the regulation of domestic worker employers.

Finally, given the stigma and very real danger of deportation of those migrant domestic workers who may have fallen out of legal migration status, our evidence suggests that there is an urgent need for the UK Government to enforce a firewall between immigration control and labour exploitation if the true scale of abuse is to be made visible and the perpetrators brought to justice.

### Implications for Practice

The UK Visa and Immigration service already offers rights-based training to migrant domestic workers via UK embassies in certain source countries.
To reduce migrant domestic workers vulnerabilities, we advocate the expansion of this training both to include explicit training related to employment and labour rights within the UK and to the rapidly expanding range of new source countries from where migrant domestic workers are now drawn.

### Methodological Contributions

This study makes several methodological contributions to the estimation of prevalence in hidden and hard-to-reach populations:

Dual conceptualisation of exploitation: We introduce two distinct approaches to operationalising exploitation.
First, we treat exploitation as a binary outcome (exploited versus not exploited), enabling direct comparison of prevalence estimates across RDS and NSUM methods.
Second, we construct a continuous risk index, acknowledging that all domestic workers may be exposed to some degree of exploitation risk.
To our knowledge, this is the first application of model-assisted RDS estimators to quantify a continuous measure of exploitation risk.

Bayesian parameter sensitivity: @fig-parameter-comparison demonstrates the importance of appropriate MCMC parameter selection for Bayesian model-assisted estimation.
Our analysis shows that enhanced parameters (featuring longer burn-in periods and more iterations) are particularly crucial for numeric and ordinal variables, where standard parameters may suffer from convergence issues.
This methodological innovation ensures robust credible interval estimation for continuous risk measures.

*Combining RDS and NSUM on the same survey instrument*: By designing a survey that captures both ego and alter information, we are able to apply RDS and NSUM to the same sample.
This dual approach has rarely been implemented in studies of labour exploitation.
It provides an opportunity to cross-validate results and assess the robustness of prevalence estimates.

*Novel bootstrap procedure for NSUM*: Recognising the non-random nature of an RDS sample, we developed a three-step bootstrap procedure tailored for NSUM estimation.
This resamples respondents, recalculates weights, and re-estimates NSUM prevalence at each iteration.
The procedure captures multiple layers of uncertainty and produces more reliable confidence intervals than conventional methods, particularly in small samples.

*Application to domestic workers in the UK*: Finally, by applying these methods to a population that is both highly stigmatised and under-researched, we demonstrate the feasibility of using advanced network-based estimation techniques in contexts where traditional sampling is impossible.
This methodological innovation has potential applications in studies of other hidden labour markets and vulnerable populations.

### Limitations of the Study

As with any empirical research, our study is subject to limitations.
In terms of nationality, our sample is not representative of the demographics of those domestic workers employed on Overseas Domestic Worker Visas in 2022 the UK.
Due to the increasing number of workers on Overseas Domestic Work visas from the Indian sub-continent, attempts were made also to seed respondents from this community.
This proved difficult, with anecdotal information suggesting that domestic workers from this community rarely had access to a personal mobile phone.
It is not therefore possible to infer the nature and extent of labour exploitation within this sub-section of the domestic worker population.

As the network structure of our sample demonstrates, even with a well-designed incentive scheme it proved difficult to recruit respondents from these communities of domestic workers in subsequent sampling waves in the time available.
Most of our respondents are therefore original sample members draw from the three domestic worker communities used to seed the survey.

### Further Research

We believe that web-RDS combined with statistical estimators such as NSUM offers an important method for the capture and comparison of relative proportions of labour exploitation and abuse in sectors within and beyond the UK.
Network scale up methods, and potential enhancements such as Generalised network scale up estimators offer to enhance understanding, not least within operations and supply chain management research, of the extent of labour exploitation in different sectors and across industries.

## Conclusion

\newpage

<!-- \newpage -->

<!-- ```{=latex} -->

<!-- \printbibliography -->

<!-- ``` -->

\newpage

## References

::: {#refs}
:::

<!-- This will be populated by Pandoc if you use --citeproc and a .bib file -->

\newpage

```{=latex}
\appendix
```

## Appendix A {#app-survey}

Population Parameters

Use \~980,000 as UK domestic worker population estimate (EU data)

Use 44,360 as NRM adult referrals baseline Address treatment of "don't know" responses and zero network size claims Consider separate analysis for Filipino subgroup


### The Survey

(From codebook)

Compare corresponding survey questions between RDS and NSUM methods:

-   Q70/Q71 (document withholding)
-   Q39+Q42/Q43 (pay issues)
-   Q45+Q47+Q48/Q49 (abuse/threats)
-   Q61+Q62/Q64 (excessive hours)
-   Q78/Q79 (access to help)

Risk Index Implementation

-   Clean coding for 13 risk categories with proper weightings
-   NRM referral (0.35)
-   Forced labor indicators (0.55 total)
-   Below minimum wage (0.10)

### Data Processing {#app-dataprep}

The process of coding variables to make them comparable across the Respondent-Driven Sampling (RDS) and Network Scale-Up Method (NSUM) estimations is a multi-step procedure that moves from conceptual mapping to specific data transformations.
The core challenge is bridging the "egocentric" questions (about the respondent's own experiences, used for RDS) with the network-based questions (about how many others the respondent knows with certain experiences, used for NSUM).
Yes, the sources provide extensive detail on the coding of variables to make them comparable for RDS and NSUM estimation.
The fundamental challenge is to create a fair comparison between the "egocentric" RDS questions (about personal experience) and the broader "how many do you know" NSUM questions.
This was accomplished by first identifying thematic links between questions and then implementing a specific coding scheme to transform them into a consistent format.
Conceptual Mapping of Variables The team first identified sets of questions that cover the same underlying themes, even if their wording differed.
These "linking" questions were categorized by the team's confidence in their comparability.
Thematic Groups for Comparison: • Document Withholding (Most Confident): Comparing personal experience (Q70) with knowing others who lack access to their documents (Q71).
• Pay/Debt Issues (High Confidence): Linking personal experience with debt (Q39) and withheld pay (Q42) to knowing others with such problems (Q43).
• Threats/Abuse (High Confidence): Aggregating personal experiences of being forced, threatened, intimidated, or verbally abused (Q45, Q47, Q48) and comparing them to knowing others who experienced threats or force (Q49).
• Excessive Hours (Lower Confidence): Combining questions about inadequate weekly rest (Q61) and excessive overtime (Q62) to compare with knowing others who face similar labor rights issues (Q64).
The confidence is lower because the NSUM question (Q64) also asks about annual leave, which is not covered in the corresponding RDS questions.
• Access to Help (Least Confident): Matching whether the respondent personally knows where to go for help (Q78) with knowing others who do not (Q79).
Coding and Transformation Process The conceptual mapping was then put into practice through a detailed coding process, which is explicitly documented in the project's R script.
The primary goal was to convert all variables into a binary (0/1) format, representing "No" or "Yes" to experiencing or knowing someone who experienced the issue.

Key Coding Steps:

1.  Handling Ambiguous Answers: For most RDS questions, responses like "I don’t know" or "Prefer not to say" were recoded as NA (missing) to exclude them from the binary analysis.
2.  Converting Categorical RDS Variables to Binary: Questions with multiple response options (e.g., "Always," "Often," "Sometimes," "Never") were recoded into a 0/1 format. For instance, for Q70 (document withholding), the answers "Always," "Often," and "Sometimes" were all coded as 1 (indicating the presence of the issue), while "Never" was coded as 0.
3.  Aggregating Multiple RDS Questions: For themes covered by multiple egocentric questions (like "Threats/Abuse"), each individual question was first recoded into a binary 0/1 variable. These binary variables were then combined using a logical OR (\|). This means if a respondent answered "Yes" to any of the grouped questions (e.g., experiencing threats OR intimidation OR verbal abuse), the final composite RDS variable would be coded as 1. This aggregation was necessary to match the broader scope of the single corresponding NSUM question.
4.  Converting NSUM Count Variables to Binary: The NSUM questions, which asked for a numerical count (e.g., "how many do you know?"), were also converted to binary. If a respondent knew one or more people (\> 0), their answer was coded as 1; if they knew zero, it remained 0. Through this systematic process of recoding, handling missing data, and aggregating variables, the team created a set of parallel binary indicators suitable for a direct comparison between the RDS and NSUM estimation frameworks.


### Sample Characteristics

#### Recruitment Network Structure

```{r}
#| label: tbl-network
#| tbl-cap: "RDS Sample Network Characteristics"
#| echo: false
#| warning: false

library(tidyverse)
# Calculate chain statistics from recruitment network
calculate_chain_stats <- function(data) {
  # Build parent-child relationships
  chains <- data %>%
    dplyr::select(id, recruiter.id) %>%
    dplyr::mutate(
      id = as.integer(id),
      recruiter.id = as.integer(recruiter.id)
    )

  # Find all seeds (recruiter.id == -1 or NA)
  seeds <- chains %>%
    dplyr::filter(recruiter.id == -1 | is.na(recruiter.id)) %>%
    dplyr::pull(id)

  # If no seeds found, return zeros
  if (length(seeds) == 0) {
    return(list(longest = 0, mean_length = 0))
  }

  # Calculate depth for each node (distance from seed)
  get_chain_depth <- function(node_id, chains, depth = 0, visited = c()) {
    if (node_id %in% visited) return(as.numeric(depth))  # Prevent cycles
    visited <- c(visited, node_id)

    # Find children of this node
    children <- chains %>%
      dplyr::filter(recruiter.id == node_id) %>%
      dplyr::pull(id)

    if (length(children) == 0) {
      return(as.numeric(depth))  # Leaf node
    } else {
      # Return maximum depth among children
      child_depths <- vapply(children, function(child) {
        get_chain_depth(child, chains, depth + 1, visited)
      }, FUN.VALUE = numeric(1))
      return(as.numeric(max(child_depths)))
    }
  }

  # Calculate longest chain from each seed
  chain_lengths <- vapply(seeds, function(seed_id) {
    get_chain_depth(seed_id, chains)
  }, FUN.VALUE = numeric(1))

  # Calculate average chain length (mean depth from seeds)
  all_depths <- c()
  for (seed_id in seeds) {
    descendants <- chains %>%
      dplyr::filter(recruiter.id == seed_id)

    if (nrow(descendants) > 0) {
      for (desc_id in descendants$id) {
        depth_val <- get_chain_depth(desc_id, chains, depth = 1)
        all_depths <- c(all_depths, as.numeric(depth_val))
      }
    }
  }

  # Ensure we have numeric vectors
  chain_lengths <- as.numeric(chain_lengths)
  all_depths <- as.numeric(all_depths)

  return(list(
    longest = ifelse(length(chain_lengths) > 0, max(chain_lengths, na.rm = TRUE), 0),
    mean_length = ifelse(length(all_depths) > 0, mean(all_depths, na.rm = TRUE), 0)
  ))
}

chain_stats <- calculate_chain_stats(rd.dd)

network_stats <- tibble(
  Characteristic = c("Total Sample Size", "Recruitment Waves", "Average Degree",
                    "Median Degree", "Seeds", "Longest Chain", "Mean Chain Length"),
  Value = c(
    nrow(rd.dd),
    max(rd.dd$wave, na.rm = TRUE),
    round(mean(rd.dd$numRef, na.rm = TRUE), 1),
    round(median(rd.dd$numRef, na.rm = TRUE), 1),
    sum(rd.dd$recruiter.id == -1 | is.na(rd.dd$recruiter.id)),
    chain_stats$longest,
    round(chain_stats$mean_length, 1)
  )
)

network_stats %>%
  kableExtra::kbl(
    col.names = c("Characteristic", "Value"),
    booktabs = TRUE,
    align = c("l", "r"),
    caption = "RDS Sample Network Characteristics"
  ) %>%
  kableExtra::kable_styling(
    latex_options = c("striped", "hold_position"),
    bootstrap_options = c("striped", "hover"),
    full_width = FALSE,
    position = "center"
  ) %>%
  kableExtra::footnote(
    general = "Average and median degree represent the number of other domestic workers known personally (Q13). Chain length measured from seed nodes through recruitment relationships.",
    general_title = "Note:",
    footnote_as_chunk = TRUE
  )
```

#### Demographic Composition

```{r}
#| label: fig-demographics
#| fig-cap: "Sample Composition by Nationality Clusters"
#| fig-width: 8
#| fig-height: 5

# Create nationality breakdown with proper ordering
nationality_summary <- rd.dd %>%
  dplyr::group_by(nationality_cluster) %>%
  dplyr::summarise(
    n = n(),
    percent = round(n() / nrow(rd.dd) * 100, 1),
    .groups = 'drop'
  ) %>%
  dplyr::arrange(desc(n)) %>%
  dplyr::mutate(
    nationality_cluster = factor(nationality_cluster, levels = nationality_cluster),
    label_text = sprintf("%d\n(%.1f%%)", n, percent)
  )

# Create professional bar plot
ggplot(nationality_summary, aes(x = nationality_cluster, y = percent, fill = nationality_cluster)) +
  geom_col(width = 0.7, alpha = 0.9) +
  geom_text(aes(label = label_text),
            vjust = -0.3,
            size = 3.5,
            fontface = "bold") +
  scale_fill_viridis_d(option = "plasma", begin = 0.2, end = 0.8) +
  scale_y_continuous(
    expand = expansion(mult = c(0, 0.15)),
    breaks = seq(0, 100, by = 10),
    labels = function(x) paste0(x, "%")
  ) +
  labs(
    x = "Nationality Cluster",
    y = "Percentage of Sample",
    title = "Sample Distribution by Nationality Cluster",
    subtitle = sprintf("Total N = %d", nrow(rd.dd))
  ) +
  theme_minimal(base_size = 11) +
  theme(
    legend.position = "none",
    plot.title = element_text(face = "bold", size = 13, hjust = 0.5),
    plot.subtitle = element_text(size = 10, hjust = 0.5, color = "gray30"),
    axis.title = element_text(face = "bold", size = 11),
    axis.text.x = element_text(angle = 0, hjust = 0.5, size = 10),
    axis.text.y = element_text(size = 10),
    panel.grid.major.x = element_blank(),
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "white", color = NA),
    plot.background = element_rect(fill = "white", color = NA)
  )
```



## Appendix B {#app-sens}

```{r setu, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(tidyverse)
library(kableExtra)
library(ggplot2)
library(plotly)
library(DT)
library(gt)

## Load results
#load("output/rds_estimates.RData")
#load("data/processed/prepared_data.RData")
load(here("data", "processed", "prepared_data.RData"))

```

This analysis estimates the prevalence of modern slavery among domestic workers in the UK using multiple RDS methodologies.
We examine two primary indicators across various population size assumptions and estimation techniques.


### RDS Estimation Results

This section presents comprehensive RDS estimates across all population size scenarios and estimation methods.

```{r}
#| label: tbl-rds-comprehensive
#| tbl-cap: "Comprehensive RDS Estimates: Prevalence estimates for all indicators across population sizes and RDS methods (RDS-I, RDS-SS) with neighborhood bootstrap confidence intervals."
#| echo: false
#| warning: false

# Load frequentist results
if (file.exists(here("output", "frequentist_estimators_results.RData"))) {
  load(here("output", "frequentist_estimators_results.RData"))

  if (exists("frequentist_df")) {
    # Create comprehensive table excluding RDS-II
    rds_comprehensive <- frequentist_df %>%
      dplyr::filter(method_clean %in% c("RDS-I", "RDS-SS")) %>%
      dplyr::select(indicator_clean, pop_label, method_clean, estimate_with_ci) %>%
      tidyr::pivot_wider(
        names_from = c(method_clean, pop_label),
        values_from = estimate_with_ci,
        names_sep = " | "
      ) %>%
      dplyr::rename(`Indicator` = indicator_clean)

    # Reorder columns: all RDS-I first, then all RDS-SS
    rds_i_cols <- grep("^RDS-I", names(rds_comprehensive), value = TRUE)
    rds_ss_cols <- grep("^RDS-SS", names(rds_comprehensive), value = TRUE)

    rds_comprehensive <- rds_comprehensive %>%
      dplyr::select(Indicator, all_of(rds_i_cols), all_of(rds_ss_cols))

    # Clean column names for display
    col_names <- names(rds_comprehensive)
    col_names[-1] <- gsub("^RDS-I \\| ", "", col_names[-1])
    col_names[-1] <- gsub("^RDS-SS \\| ", "", col_names[-1])

    rds_comprehensive %>%
  kableExtra::kbl(
    col.names = col_names,
    booktabs = TRUE,
    align = c("l", rep("c", ncol(rds_comprehensive) - 1)),
    longtable = TRUE
  ) %>%
  kableExtra::kable_styling(
    latex_options = c("striped", "scale_down", "hold_position"),
    font_size = 8,
    full_width = FALSE      # <--- Key change here
  ) %>%
  kableExtra::add_header_above(c(
    " " = 1,
    "RDS-I Estimator" = length(rds_i_cols),
    "RDS-SS Estimator" = length(rds_ss_cols)
  )) %>%
  kableExtra::column_spec(1, bold = TRUE) %>%   # Remove or relax width argument
  kableExtra::footnote(
    general = "RDS-I: Salganik-Heckathorn estimator...",
    general_title = "Note:",
    footnote_as_chunk = TRUE,
    threeparttable = TRUE
    #longtable = TRUE
  )
  } else {
    cat("frequentist_df not found.\n")
  }
} else {
  cat("frequentist_estimators_results.RData file not found.\n")
}
```

```{r eval=FALSE}

    # Create professionally formatted table
    rds_comprehensive %>%
      kableExtra::kbl(
        col.names = col_names,
        booktabs = TRUE,
        align = c("l", rep("c", ncol(rds_comprehensive) - 1)),
        longtable = TRUE
      ) %>%
      kableExtra::kable_styling(
        latex_options = c("striped", "scale_down", "hold_position"),
        bootstrap_options = c("striped", "hover", "condensed"),
        font_size = 8,
        full_width = TRUE
      ) %>%
      kableExtra::add_header_above(c(
        " " = 1,
        "RDS-I Estimator" = length(rds_i_cols),
        "RDS-SS Estimator" = length(rds_ss_cols)
      )) %>%
      kableExtra::column_spec(1, bold = TRUE, width = "3cm") %>%
      kableExtra::footnote(
        general = "RDS-I: Salganik-Heckathorn estimator; RDS-SS: Gile's Successive Sampling estimator. Population sizes represent assumed UK domestic worker totals: 50K, 100K, 980K, and 1.74M. Estimates shown as prevalence (95% CI) from neighborhood bootstrap with 1,000 resamples.",
        general_title = "Note:",
        footnote_as_chunk = TRUE,
        threeparttable = TRUE
      )
  } else {
    cat("frequentist_df not found.\n")
  }
} else {
  cat("frequentist_estimators_results.RData file not found.\n")
}
```

```{r}
#| label: fig-rds-sensitivity-popsize
#| fig-cap: "RDS Sensitivity to Population Size: Comparison of RDS estimates across all population size scenarios. Each panel shows one RDS method with point estimates and 95% bootstrap confidence intervals varying by population size."
#| fig-width: 12
#| fig-height: 8
#| out-width: "100%"
#| echo: false
#| warning: false

library(ggplot2)

# Create faceted plot by RDS method
if (exists("frequentist_df")) {
  rds_sensitivity_plot <- frequentist_df %>%
    ggplot(aes(x = pop_label, y = estimate_pct,
               color = indicator_clean, group = indicator_clean)) +
    geom_line(linewidth = 1) +
    geom_errorbar(aes(ymin = ci_lower_pct, ymax = ci_upper_pct),
                  width = 0.2, alpha = 0.6) +
    geom_point(size = 3, aes(shape = indicator_clean)) +
    facet_wrap(~ method_clean, ncol = 3) +
    scale_color_viridis_d(name = "Indicator") +
    scale_shape_manual(values = c(15, 16, 17, 18, 19), name = "Indicator") +
    labs(
      title = "RDS Estimates Across Population Sizes",
      subtitle = "Comparison of estimation methods",
      x = "Population Size",
      y = "Estimated Prevalence (%)"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 12, face = "bold"),
      plot.subtitle = element_text(size = 10),
      strip.text = element_text(size = 10, face = "bold"),
      axis.text.x = element_text(angle = 45, hjust = 1),
      legend.position = "bottom"
    )

  print(rds_sensitivity_plot)
} else {
  cat("frequentist_df not loaded.\n")
}
```

### Model-Assisted Estimates by Population Size

```{r}
#| label: tbl-ma-estimates
#| tbl-cap: "Model-Assisted Estimates by Population Size and Seed Selection. Source: Authors' Own Work."
#| echo: false
#| warning: false
#| message: false

# Load required packages
library(dplyr)
library(tidyr)
library(kableExtra)
library(scales)
library(here)

# Function to extract MA sensitivity results
extract_ma_sensitivity <- function(indicator, pop_size, seed_method) {
  file_path <- here("output", paste0("ma_sensitivity_", indicator, "_", pop_size, "_", seed_method, ".RData"))

  if (file.exists(file_path)) {
    tryCatch({
      load(file_path)

      # The MA result should be in ma_result variable
      if (exists("ma_result") && !is.null(ma_result$estimate)) {
        estimates <- ma_result$estimate$estimate
        if ("1" %in% names(estimates)) {
          prevalence <- estimates["1"]

          # Construct CI using variance estimate
          if (!is.null(ma_result$varest) && !is.na(ma_result$varest)) {
            se <- sqrt(ma_result$varest)
            ci_lower <- pmax(0, prevalence - 1.96 * se)
            ci_upper <- pmin(1, prevalence + 1.96 * se)
          } else {
            ci_lower <- NA
            ci_upper <- NA
          }

          return(list(
            estimate = as.numeric(prevalence),
            ci_lower = as.numeric(ci_lower),
            ci_upper = as.numeric(ci_upper)
          ))
        }
      }
      return(list(estimate = NA, ci_lower = NA, ci_upper = NA))
    }, error = function(e) {
      return(list(estimate = NA, ci_lower = NA, ci_upper = NA))
    })
  }

  return(list(estimate = NA, ci_lower = NA, ci_upper = NA))
}

# Create comparison table using available sensitivity analysis results
ma_comparison <- expand_grid(
  seed_method = c("sample", "random", "degree"),
  pop_size = c(50000, 100000, 980000, 1740000),
  indicator = c("document_withholding_rds", "pay_issues_rds", "excessive_hours_rds", "threats_abuse_rds")
) %>%
  rowwise() %>%
  mutate(
    result = list(extract_ma_sensitivity(indicator, pop_size, seed_method)),
    estimate = result$estimate,
    ci_lower = result$ci_lower,
    ci_upper = result$ci_upper
  ) %>%
  ungroup() %>%
  select(-result) %>%
  filter(!is.na(estimate))

# Check if we have any data
if (nrow(ma_comparison) > 0) {
  # Create formatted table
  ma_formatted <- ma_comparison %>%
    mutate(
      pop_size_f = scales::comma(pop_size),
      estimate_ci = sprintf("%.1f%% (%.1f%%, %.1f%%)",
                           estimate * 100, ci_lower * 100, ci_upper * 100),
      indicator_clean = case_when(
        indicator == "document_withholding_rds" ~ "Document Withholding",
        indicator == "pay_issues_rds" ~ "Pay Issues",
        indicator == "excessive_hours_rds" ~ "Excessive Hours",
        indicator == "threats_abuse_rds" ~ "Threats/Abuse",
        TRUE ~ indicator
      )
    ) %>%
    select(seed_method, pop_size_f, indicator_clean, estimate_ci) %>%
    pivot_wider(names_from = indicator_clean, values_from = estimate_ci)

  # Get column names after pivot
  indicator_cols <- setdiff(names(ma_formatted), c("seed_method", "pop_size_f"))

  # Create nice column names
  col_names <- c("Seed Selection", "Population Size", indicator_cols)

  # Create table with kableExtra
  ma_formatted %>%
    kableExtra::kbl(
      col.names = col_names,
      booktabs = TRUE,
      align = c("l", "r", rep("r", length(indicator_cols)))
    ) %>%
    kableExtra::kable_styling(
      latex_options = c("striped", "scale_down", "hold_position"),
      bootstrap_options = c("striped", "hover", "condensed"),
      font_size = 9,
      full_width = TRUE
    ) %>%
    kableExtra::add_header_above(c(" " = 2, "Prevalence Estimates (95% CrI)" = length(indicator_cols))) %>%
    kableExtra::footnote(
      general = "Model-Assisted estimates from Gile & Handcock (2015) Bayesian inference. CrI = Credible Interval from posterior distribution.",
      general_title = "Note:",
      footnote_as_chunk = TRUE
    )

} else {
  cat("No Model-Assisted sensitivity results available.\n")
}
```

#### Traditional RDS Estimators Comparison

```{r}
#| label: tbl-rds-comparison
#| tbl-cap: "RDS Estimator Comparison for Binary Indicators. Source: Authors' Own Work."
#| echo: false
#| warning: false
#| message: false

# Create a placeholder table for RDS results
# This would normally load from saved RDS estimation results

# Check if RDS results are available
rds_file <- here("output", "rds_estimates.RData")

if (file.exists(rds_file)) {
  load(rds_file)

  if (exists("rds_results") && "980000" %in% names(rds_results)) {
    rds_980k <- rds_results[["980000"]]

    # Get available indicators
    available_indicators <- intersect(
      names(rds_980k$rds_i),
      c("document_withholding_rds", "pay_issues_rds", "threats_abuse_rds", "excessive_hours_rds", "access_to_help_rds")
    )

    if (length(available_indicators) > 0) {
      # Create table with available indicators
      rds_comparison_data <- tibble(
        Method = rep(c("RDS-I", "RDS-II", "RDS-SS"), length(available_indicators)),
        Indicator = rep(available_indicators, each = 3)
      )

      rds_comparison_data <- rds_comparison_data %>%
        rowwise() %>%
        mutate(
          estimate = case_when(
            Method == "RDS-I" ~ rds_980k$rds_i[[Indicator]]$estimate,
            Method == "RDS-II" ~ rds_980k$rds_ii[[Indicator]]$estimate,
            Method == "RDS-SS" ~ rds_980k$rds_ss[[Indicator]]$estimate,
            TRUE ~ NA_real_
          ),
          ci_lower = case_when(
            Method == "RDS-I" ~ rds_980k$rds_i[[Indicator]]$conf.int[1],
            Method == "RDS-II" ~ rds_980k$rds_ii[[Indicator]]$conf.int[1],
            Method == "RDS-SS" ~ rds_980k$rds_ss[[Indicator]]$conf.int[1],
            TRUE ~ NA_real_
          ),
          ci_upper = case_when(
            Method == "RDS-I" ~ rds_980k$rds_i[[Indicator]]$conf.int[2],
            Method == "RDS-II" ~ rds_980k$rds_ii[[Indicator]]$conf.int[2],
            Method == "RDS-SS" ~ rds_980k$rds_ss[[Indicator]]$conf.int[2],
            TRUE ~ NA_real_
          )
        ) %>%
        ungroup() %>%
        mutate(
          estimate_ci = sprintf("%.1f%% (%.1f%%, %.1f%%)",
                               estimate * 100, ci_lower * 100, ci_upper * 100),
          indicator_clean = case_when(
            Indicator == "document_withholding_rds" ~ "Document Withholding",
            Indicator == "pay_issues_rds" ~ "Pay Issues",
            Indicator == "threats_abuse_rds" ~ "Threats/Abuse",
            Indicator == "excessive_hours_rds" ~ "Excessive Hours",
            Indicator == "access_to_help_rds" ~ "Access to Help",
            TRUE ~ Indicator
          )
        ) %>%
        select(Method, indicator_clean, estimate_ci) %>%
        pivot_wider(names_from = indicator_clean, values_from = estimate_ci)

      # Create table
      rds_comparison_data %>%
        gt() %>%
        tab_header(title = "RDS Estimator Comparison (Population: 980,000)") %>%
        cols_label(Method = "RDS Method") %>%
        tab_spanner(label = "Prevalence Estimates (95% CI)",
                   columns = -Method) %>%
        fmt_missing(columns = everything(), missing_text = "—") %>%
        tab_options(
          table.font.size = px(9),
          table.width = pct(85),
          column_labels.font.size = px(8)

        )

    } else {
    }
  } else {
  }
} else {
}
```

<!-- ### Subgroup Analysis -->

<!-- ```{r} -->
<!-- #| label: netclust-analysis2 -->
<!-- #| fig-cap: "Clustered SS-PSE prevalence estimates for labour exploitation indicators" -->
<!-- #| fig-width: 12 -->
<!-- #| fig-height: 8 -->
<!-- #| echo: false -->
<!-- #| warning: false -->
<!-- #| message: false -->

<!-- # Load required libraries -->
<!-- library(tidyverse) -->
<!-- library(knitr) -->
<!-- library(kableExtra) -->
<!-- library(here) -->
<!-- library(scales) -->
<!-- library(viridis) -->

<!-- # Load netclust results -->
<!-- load(here("output", "netclust_subgroup_analysis_results_FIXED.RData")) -->

<!-- # ===== TABLE: Netclust Results Summary ===== -->
<!-- netclust_table <- final_results$summary_df %>% -->
<!--   mutate( -->
<!--     indicator_label = case_when( -->
<!--       indicator == "document_withholding_rds" ~ "Document withholding", -->
<!--       indicator == "pay_issues_rds" ~ "Pay-related issues", -->
<!--       indicator == "threats_abuse_rds" ~ "Threats/abuse", -->
<!--       indicator == "excessive_hours_rds" ~ "Excessive hours", -->
<!--       indicator == "access_to_help_rds" ~ "Limited access to help", -->
<!--       TRUE ~ indicator -->
<!--     ), -->
<!--     # Convert to percentage for clearer presentation -->
<!--     prevalence_pct = round(estimate_pct, 3), -->
<!--     ci_lower_pct = round(ci_lower_pct, 3), -->
<!--     ci_upper_pct = round(ci_upper_pct, 3), -->
<!--     prevalence_display = paste0(prevalence_pct, "% (", ci_lower_pct, "–", -->
<!-- ci_upper_pct, "%)") -->
<!--   ) %>% -->
<!--   select( -->
<!--     Indicator = indicator_label, -->
<!--     "Prevalence (95% CI)" = prevalence_display, -->
<!--     "Sample with trait" = n_trait, -->
<!--     "Total sample" = n_obs -->
<!--   ) -->

<!-- # Display table -->
<!-- knitr::kable(netclust_table, -->
<!--              caption = "Clustered SS-PSE prevalence estimates for labour exploitation indicators among domestic workers", -->
<!--              booktabs = TRUE, linesep="") %>% -->
<!--   kable_styling(latex_options = c("striped", "scale_down", -->
<!-- "hold_position")) %>% -->
<!--   footnote(general = "Estimates based on Clustered Sequential Sampling Population Size Estimation (Clustered SS-PSE) methodology using netclust package. Population size assumption: 980,000 UK domestic workers. Confidence intervals derived from MCMC sampling (1,000 samples, 2,000 burn-in). Analysis accounts for nationality clustering (Filipino, Latinx, Other Combined) and network structure in RDS data.", -->
<!--            general_title = "Note: ") -->

<!-- # ===== VISUALIZATION 1: Forest Plot ===== -->
<!-- plot_data <- final_results$summary_df %>% -->
<!--   mutate( -->
<!--     indicator_label = case_when( -->
<!--       indicator == "document_withholding_rds" ~ "Document\nwithholding", -->
<!--       indicator == "pay_issues_rds" ~ "Pay-related\nissues", -->
<!--       indicator == "threats_abuse_rds" ~ "Threats/\nabuse", -->
<!--       indicator == "excessive_hours_rds" ~ "Excessive\nhours", -->
<!--       indicator == "access_to_help_rds" ~ "Limited access\nto help", -->
<!--       TRUE ~ indicator -->
<!--     ), -->
<!--     indicator_label = fct_reorder(indicator_label, estimate_pct) -->
<!--   ) -->

<!-- forest_plot <- ggplot(plot_data, aes(x = indicator_label, y = -->
<!-- estimate_pct)) + -->
<!--   geom_point(size = 4, color = "#2c3e50") + -->
<!--   geom_errorbar(aes(ymin = ci_lower_pct, ymax = ci_upper_pct), -->
<!--                 width = 0.2, linewidth = 1, color = "#2c3e50") + -->
<!--   coord_flip() + -->
<!--   scale_y_continuous(labels = percent_format(scale = 1, suffix = "%"), -->
<!--                      trans = "log10", -->
<!--                      breaks = c(0.01, 0.1, 1, 10)) + -->
<!--   labs( -->
<!--     title = "Clustered SS-PSE Prevalence Estimates", -->
<!--     subtitle = "Labour exploitation indicators among UK domestic workers", -->
<!--     x = "Exploitation Indicator", -->
<!--     y = "Prevalence (%) with 95% Confidence Intervals (log scale)", -->
<!--     caption = "Based on RDS sample (n=85) with nationality clustering. Population assumption: 980,000." -->
<!--   ) + -->
<!--   theme_minimal(base_size = 12) + -->
<!--   theme( -->
<!--     plot.title = element_text(size = 14, face = "bold"), -->
<!--     plot.subtitle = element_text(size = 12), -->
<!--     axis.text = element_text(size = 11), -->
<!--     panel.grid.minor = element_blank(), -->
<!--     plot.caption = element_text(size = 9, color = "gray60") -->
<!--   ) -->

<!-- print(forest_plot) -->

<!-- # ===== VISUALIZATION 2: Sample Composition ===== -->
<!-- sample_comp <- final_results$summary_df %>% -->
<!--   mutate( -->
<!--     indicator_label = case_when( -->
<!--       indicator == "document_withholding_rds" ~ "Document\nwithholding", -->
<!--       indicator == "pay_issues_rds" ~ "Pay-related\nissues", -->
<!--       indicator == "threats_abuse_rds" ~ "Threats/\nabuse", -->
<!--       indicator == "excessive_hours_rds" ~ "Excessive\nhours", -->
<!--       indicator == "access_to_help_rds" ~ "Limited access\nto help", -->
<!--       TRUE ~ indicator -->
<!--     ), -->
<!--     prop_with_trait = n_trait / n_obs, -->
<!--     prop_without_trait = 1 - prop_with_trait -->
<!--   ) %>% -->
<!--   select(indicator_label, prop_with_trait, prop_without_trait) %>% -->
<!--   pivot_longer(cols = c(prop_with_trait, prop_without_trait), -->
<!--                names_to = "category", -->
<!--                values_to = "proportion") %>% -->
<!--   mutate( -->
<!--     category = if_else(category == "prop_with_trait", "With trait", -->
<!-- "Without trait"), -->
<!--     category = factor(category, levels = c("Without trait", "With trait")) -->
<!--   ) -->

<!-- comp_plot <- ggplot(sample_comp, aes(x = indicator_label, y = proportion, -->
<!-- fill = category)) + -->
<!--   geom_col(position = "stack", alpha = 0.8) + -->
<!--   scale_fill_manual(values = c("Without trait" = "#bdc3c7", "With trait" = -->
<!--  "#e74c3c")) + -->
<!--   scale_y_continuous(labels = percent_format()) + -->
<!--   coord_flip() + -->
<!--   labs( -->
<!--     title = "Sample Composition by Exploitation Indicator", -->
<!--     subtitle = "Proportion of respondents with each indicator present", -->
<!--     x = "Exploitation Indicator", -->
<!--     y = "Proportion of Sample", -->
<!--     fill = "Category", -->
<!--     caption = "Total sample size: 85 domestic workers" -->
<!--   ) + -->
<!--   theme_minimal(base_size = 12) + -->
<!--   theme( -->
<!--     plot.title = element_text(size = 14, face = "bold"), -->
<!--     plot.subtitle = element_text(size = 12), -->
<!--     axis.text = element_text(size = 11), -->
<!--     legend.position = "bottom", -->
<!--     panel.grid.minor = element_blank(), -->
<!--     plot.caption = element_text(size = 9, color = "gray60") -->
<!--   ) -->

<!-- print(comp_plot) -->

<!-- # ===== VISUALIZATION 3: Convergence Diagnostics ===== -->
<!-- if(length(final_results$individual_results) > 0) { -->
<!--   # Extract MCMC diagnostics from first result as example -->
<!--   sample_result <- final_results$individual_results[[1]] -->
<!--   mcmc_samples <- sample_result$netclust_output$sample[, "N"] -->

<!--   # Create trace plot -->
<!--   trace_data <- data.frame( -->
<!--     iteration = 1:length(mcmc_samples), -->
<!--     population_size = mcmc_samples -->
<!--   ) -->

<!--   trace_plot <- ggplot(trace_data, aes(x = iteration, y = -->
<!-- population_size)) + -->
<!--     geom_line(alpha = 0.7, color = "#3498db") + -->
<!--     labs( -->
<!--       title = "MCMC Trace Plot: Population Size Estimates", -->
<!--       subtitle = paste("Example from", -->
<!-- names(final_results$individual_results)[1]), -->
<!--       x = "MCMC Iteration", -->
<!--       y = "Estimated Population Size", -->
<!--       caption = "1,000 MCMC samples after 2,000 burn-in iterations" -->
<!--     ) + -->
<!--     theme_minimal(base_size = 12) + -->
<!--     theme( -->
<!--       plot.title = element_text(size = 14, face = "bold"), -->
<!--       plot.subtitle = element_text(size = 12), -->
<!--       panel.grid.minor = element_blank(), -->
<!--       plot.caption = element_text(size = 9, color = "gray60") -->
<!--     ) -->

<!--   print(trace_plot) -->
<!-- } -->

<!-- # ===== DETAILED RESULTS SUMMARY ===== -->
<!-- cat("\n=== NETCLUST ANALYSIS SUMMARY ===\n") -->
<!-- cat("Analysis Configuration:\n") -->
<!-- cat("- Population size assumption:", -->
<!-- format(final_results$config$baseline_population, big.mark = ","), "UK -->
<!-- domestic workers\n") -->
<!-- cat("- MCMC samples:", final_results$config$samplesize, "\n") -->
<!-- cat("- Burn-in iterations:", final_results$config$burnin, "\n") -->
<!-- cat("- Number of nationality clusters:", -->
<!-- final_results$individual_results[[1]]$n_clusters, "\n") -->
<!-- cat("- Total sample size:", final_results$individual_results[[1]]$n_obs, -->
<!-- "\n") -->

<!-- cat("\nCluster composition:\n") -->
<!-- cluster_info <- final_results$individual_results[[1]]$netclust_output$nc -->
<!-- names(cluster_info) <- c("Filipino", "Latinx", "Other Combined") -->
<!-- for(i in 1:length(cluster_info)) { -->
<!--   cat("-", names(cluster_info)[i], ":", cluster_info[i], "respondents\n") -->
<!-- } -->

<!-- cat("\nKey Findings:\n") -->
<!-- cat("- Highest prevalence: Excessive hours (0.3%)\n") -->
<!-- cat("- Lowest prevalence: Document withholding (0.1%)\n") -->
<!-- cat("- All estimates show successful MCMC convergence\n") -->
<!-- cat("- Wide confidence intervals reflect uncertainty in hidden population -->
<!-- estimation\n") -->
<!-- ``` -->

### Model-Assisted Sensitivity Analysis

This section presents comprehensive sensitivity analysis for Model-Assisted inference estimates across all exploitation indicators, examining robustness to population size assumptions and seed selection methods.

```{r}
#| label: extract-all-ma-sensitivity
#| echo: false
#| warning: false
#| message: false

# Extract all MA sensitivity results across all parameters
# File naming: ma_sensitivity_{indicator}_{popsize}_{seed_method}.RData

# Define all parameters
indicators <- c(
  "document_withholding_rds",
  "pay_issues_rds",
  "threats_abuse_rds",
  "excessive_hours_rds",
  "access_to_help_rds",
  "whether_exploitation"
)

indicator_labels <- c(
  "document_withholding_rds" = "Document Withholding",
  "pay_issues_rds" = "Pay-Related Issues",
  "threats_abuse_rds" = "Threats/Abuse",
  "excessive_hours_rds" = "Excessive Hours",
  "access_to_help_rds" = "Limited Access to Help",
  "whether_exploitation" = "Any Exploitation"
)

population_sizes <- c(50000, 100000, 980000, 1740000)
seed_methods <- c("degree", "random", "sample")

# Function to extract estimates from sensitivity files
extract_sensitivity_estimate <- function(indicator, pop_size, seed_method) {
  file_path <- here("output", paste0("ma_sensitivity_", indicator, "_",
                                     pop_size, "_", seed_method, ".RData"))

  if (file.exists(file_path)) {
    load(file_path)
    if (exists("ma_result") && !is.null(ma_result$estimate)) {
      interval <- ma_result$estimate$interval
      if (length(interval) >= 6) {
        return(data.frame(
          indicator = indicator,
          label = indicator_labels[indicator],
          pop_size = pop_size,
          seed_method = seed_method,
          prevalence = as.numeric(interval[2]),
          ci_lower = as.numeric(interval[4]),
          ci_upper = as.numeric(interval[6]),
          stringsAsFactors = FALSE
        ))
      }
    }
  }
  return(NULL)
}

# Extract all combinations
all_sensitivity_results <- list()
for (ind in indicators) {
  for (pop in population_sizes) {
    for (seed in seed_methods) {
      result <- extract_sensitivity_estimate(ind, pop, seed)
      if (!is.null(result)) {
        all_sensitivity_results[[length(all_sensitivity_results) + 1]] <- result
      }
    }
  }
}

# Combine into single dataframe
sensitivity_df <- dplyr::bind_rows(all_sensitivity_results) %>%
  dplyr::mutate(
    prevalence_pct = prevalence * 100,
    ci_lower_pct = ci_lower * 100,
    ci_upper_pct = ci_upper * 100,
    pop_size_label = factor(
      pop_size,
      levels = c(50000, 100000, 980000, 1740000),
      labels = c("50K", "100K", "980K", "1.74M")
    ),
    seed_method_label = factor(
      seed_method,
      levels = c("degree", "random", "sample"),
      labels = c("Degree", "Random", "Sample")
    )
  )
```

```{r}
#| label: tbl-ma-sensitivity-full
#| tbl-cap: "Model-Assisted Sensitivity Analysis: Point estimates and 95% credible intervals across all parameter combinations. Estimates from Gile & Handcock (2015) Bayesian Model-Assisted inference."
#| echo: false
#| warning: false

if (nrow(sensitivity_df) > 0) {
  # Create comprehensive comparison table - grouped by seed method for clarity
  sensitivity_table <- sensitivity_df %>%
    dplyr::mutate(
      estimate_ci = sprintf("%.1f%% (%.1f-%.1f%%)",
                           prevalence_pct, ci_lower_pct, ci_upper_pct)
    ) %>%
    dplyr::select(label, pop_size_label, seed_method_label, estimate_ci) %>%
    tidyr::pivot_wider(
      names_from = c(seed_method_label, pop_size_label),
      values_from = estimate_ci,
      names_sep = ": "
    )

  # Count actual columns for dynamic header
  n_cols <- ncol(sensitivity_table)

  sensitivity_table %>%
    kableExtra::kbl(
      booktabs = TRUE,
      align = c("l", rep("r", n_cols - 1)),
      caption = "Model-Assisted Sensitivity Analysis: Point estimates and 95% credible intervals"
    ) %>%
    kableExtra::kable_styling(
      latex_options = c("striped", "scale_down", "hold_position"),
      bootstrap_options = c("striped", "hover", "condensed"),
      font_size = 7,
      full_width = TRUE
    ) %>%
    kableExtra::footnote(
      general = "Estimates from Gile & Handcock (2015) Bayesian Model-Assisted inference. Population sizes: 50K, 100K, 980K, 1.74M domestic workers. Seed methods: Degree (by network degree), Random, Sample (from data). CrI = Bayesian credible interval.",
      general_title = "Note:",
      footnote_as_chunk = TRUE
    )
} else {
  cat("No sensitivity analysis data available.\n")
}
```

```{r}
#| label: fig-ma-sensitivity-by-indicator
#| fig-cap: "Model-Assisted Sensitivity by Population Size and Seed Selection: Point estimates with 95% credible intervals for each exploitation indicator across all parameter combinations. Each panel shows one indicator with estimates varying by population size (color) and seed selection method (shape)."
#| fig-width: 10
#| fig-height: 12
#| out-width: "100%"
#| echo: false
#| warning: false

library(ggplot2)

# Only create plot if we have data
if (nrow(sensitivity_df) > 0) {
  # Get unique population sizes for shapes
  n_popsizes <- length(unique(sensitivity_df$pop_size_label))
  shape_values <- c(15, 16, 17, 18)[1:n_popsizes]

  # Create faceted plot by indicator
  sensitivity_plot <- sensitivity_df %>%
    ggplot(aes(x = seed_method_label, y = prevalence_pct,
               color = pop_size_label, group = pop_size_label)) +
    geom_line(alpha = 0.5) +
    geom_errorbar(aes(ymin = ci_lower_pct, ymax = ci_upper_pct),
                  width = 0.2, alpha = 0.6) +
    geom_point(size = 3, aes(shape = pop_size_label)) +
    geom_text(aes(label = sprintf("%.1f%%", prevalence_pct)),
              vjust = -0.8, size = 2.5, show.legend = FALSE) +
    facet_wrap(~ label, scales = "free_y", ncol = 2) +
    scale_color_viridis_d(name = "Population Size") +
    scale_shape_manual(values = shape_values, name = "Population Size") +
    labs(
      title = "Sensitivity of MA Estimates to Population Size and Seed Selection",
      subtitle = "Gile & Handcock (2015) Bayesian Model-Assisted Inference",
      x = "Seed Selection Method",
      y = "Estimated Prevalence (%)"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 12, face = "bold"),
      plot.subtitle = element_text(size = 10),
      strip.text = element_text(size = 10, face = "bold"),
      axis.text.x = element_text(angle = 45, hjust = 1),
      legend.position = "bottom"
    )

  print(sensitivity_plot)
} else {
  cat("No sensitivity data available for plotting.\n")
}
```

```{r}
#| label: fig-ma-sensitivity-comparison
#| fig-cap: "Model-Assisted Point Estimate Comparison: Direct comparison of point estimates across all indicators, fixing population size at 980K. Lines connect estimates using the same seed selection method, showing consistency across indicators."
#| fig-width: 10
#| fig-height: 6
#| out-width: "95%"
#| echo: false
#| warning: false

# Create comparison plot fixing population at 980K
comparison_data <- sensitivity_df %>%
  dplyr::filter(pop_size == 980000)

if (nrow(comparison_data) > 0) {
  comparison_plot <- comparison_data %>%
    dplyr::mutate(
      label_ordered = factor(label, levels = indicator_labels[indicators])
    ) %>%
    ggplot(aes(x = label_ordered, y = prevalence_pct,
               color = seed_method_label, group = seed_method_label)) +
    geom_line(linewidth = 1) +
    geom_errorbar(aes(ymin = ci_lower_pct, ymax = ci_upper_pct),
                  width = 0.3, alpha = 0.6, linewidth = 0.8) +
    geom_point(size = 4, aes(shape = seed_method_label)) +
    geom_text(aes(label = sprintf("%.1f%%", prevalence_pct)),
              vjust = -1.2, size = 3, show.legend = FALSE) +
    scale_color_brewer(palette = "Set1", name = "Seed Selection") +
    scale_shape_manual(values = c(15, 16, 17), name = "Seed Selection") +
    labs(
      title = "MA Estimates Across Indicators (N = 980,000)",
      subtitle = "Comparison of seed selection methods",
      x = "Exploitation Indicator",
      y = "Estimated Prevalence (%)"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 12, face = "bold"),
      plot.subtitle = element_text(size = 10),
      axis.text.x = element_text(angle = 45, hjust = 1, size = 9),
      legend.position = "bottom"
    )

  print(comparison_plot)
} else {
  cat("No data available for population size 980,000.\n")
}
```

### NSUM Sensitivity Analysis {#app-nsum-sens}

The NSUM estimates presented in the main text (Section 5.2.3) used neighborhood bootstrap resampling, Sequential Sampling weights, and the Modified Basic Scale-Up (MBSU) estimator with a population size of 980,000. To assess the robustness of these findings, we conducted comprehensive sensitivity analyses varying four key methodological choices: (1) bootstrap method, (2) weighting scheme, (3) population size assumption, and (4) NSUM estimator specification.

#### Sensitivity to Bootstrap Method

We compared four bootstrap resampling approaches: neighborhood bootstrap, tree bootstrap, chain bootstrap, and sequential sampling bootstrap. As shown in @tbl-appendix-bootstrap, all methods produce nearly identical point estimates, with variation only in confidence interval widths. This demonstrates that our findings are robust to the choice of bootstrap method, with the neighborhood bootstrap providing slightly more conservative (wider) confidence intervals than alternative approaches.

```{r}
#| label: tbl-appendix-bootstrap
#| tbl-cap: "Sensitivity Analysis: Bootstrap Method Comparison. All estimates use SS weights, N=980,000, and MBSU (Moderate) adjustment. Source: Authors' Own Work."
#| echo: false
#| warning: false
#| message: false

library(tidyverse)
library(kableExtra)

bootstrap_file <- here("output", "tables", "AppendixA1_bootstrap_comparison.csv")
if (file.exists(bootstrap_file)) {
  boot_comp <- read_csv(bootstrap_file, show_col_types = FALSE)

  boot_comp %>%
    kbl(
      col.names = c("Bootstrap Method", "Outcome", "Point Estimate",
                    "95% CI Lower", "95% CI Upper", "Prevalence (%)"),
      booktabs = TRUE,
      align = c("l", "l", "r", "r", "r", "l"),
      format.args = list(big.mark = ",")
    ) %>%
    kable_styling(
      latex_options = c("striped", "hold_position", "scale_down"),
      bootstrap_options = c("striped", "hover", "condensed"),
      full_width = FALSE,
      font_size = 8
    ) %>%
    footnote(
      general = "All estimates use Sequential Sampling weights, population size of 980,000, and MBSU estimator with moderate adjustments (δ=0.9, τ=0.85).",
      general_title = "Note:",
      footnote_as_chunk = TRUE
    )
} else {
  cat("Bootstrap comparison file not found.\n")
}
```

#### Sensitivity to Weight Method

We compared Volz-Heckathorn (VH) and Sequential Sampling (SS) weighting schemes (@tbl-appendix-weights). Results were identical for both methods, as both approaches appropriately account for the RDS sampling design and degree-based inclusion probabilities. This validates our choice of SS weights for the main analysis.

```{r}
#| label: tbl-appendix-weights
#| tbl-cap: "Sensitivity Analysis: Weight Method Comparison. All estimates use neighborhood bootstrap, N=980,000, and MBSU (Moderate) adjustment. Source: Authors' Own Work."
#| echo: false
#| warning: false
#| message: false

weight_file <- here("output", "tables", "AppendixA2_weight_comparison.csv")
if (file.exists(weight_file)) {
  weight_comp <- read_csv(weight_file, show_col_types = FALSE)

  weight_comp %>%
    kbl(
      col.names = c("Weight Method", "Outcome", "Point Estimate",
                    "95% CI Lower", "95% CI Upper", "Prevalence (%)"),
      booktabs = TRUE,
      align = c("l", "l", "r", "r", "r", "l"),
      format.args = list(big.mark = ",")
    ) %>%
    kable_styling(
      latex_options = c("striped", "hold_position", "scale_down"),
      bootstrap_options = c("striped", "hover", "condensed"),
      full_width = FALSE,
      font_size = 8
    ) %>%
    footnote(
      general = "VH = Volz-Heckathorn weights; SS = Sequential Sampling weights. Both methods produce identical estimates as expected for RDS data.",
      general_title = "Note:",
      footnote_as_chunk = TRUE
    )
} else {
  cat("Weight comparison file not found.\n")
}
```

#### Sensitivity to Population Size

We tested four population size scenarios: 50,000, 100,000, 980,000, and 1,740,000 (@tbl-appendix-popsize). As expected, absolute counts scaled linearly with population size assumptions, while prevalence rates remained constant. This validates our estimation approach and demonstrates that the choice of population size affects the scale but not the proportional prevalence estimates.

```{r}
#| label: tbl-appendix-popsize
#| tbl-cap: "Sensitivity Analysis: Population Size Comparison. All estimates use neighborhood bootstrap, SS weights, and MBSU (Moderate) adjustment. Source: Authors' Own Work."
#| echo: false
#| warning: false
#| message: false

popsize_file <- here("output", "tables", "AppendixA3_popsize_comparison.csv")
if (file.exists(popsize_file)) {
  popsize_comp <- read_csv(popsize_file, show_col_types = FALSE)

  popsize_comp %>%
    kbl(
      col.names = c("Population Size", "Outcome", "Point Estimate",
                    "95% CI Lower", "95% CI Upper", "Prevalence (%)"),
      booktabs = TRUE,
      align = c("r", "l", "r", "r", "r", "l"),
      format.args = list(big.mark = ",")
    ) %>%
    kable_styling(
      latex_options = c("striped", "hold_position", "scale_down"),
      bootstrap_options = c("striped", "hover", "condensed"),
      full_width = FALSE,
      font_size = 8
    ) %>%
    footnote(
      general = "Prevalence rates remain constant across population sizes, demonstrating validity of estimation approach. We use N=980,000 as our baseline estimate of UK domestic worker population.",
      general_title = "Note:",
      footnote_as_chunk = TRUE
    )
} else {
  cat("Population size comparison file not found.\n")
}
```

#### Sensitivity to NSUM Method and Adjustment Factors

The choice of NSUM estimator and adjustment factors had substantial impact on estimates (@tbl-appendix-nsum-method). We compared MBSU with three adjustment factor sets (no adjustment, moderate, conservative) and GNSUM Symmetric estimation. GNSUM estimates matched MBSU (No Adjustment) exactly for all indicators, while conservative MBSU adjustments (δ=0.8, τ=0.7) produced estimates approximately 1.8 times higher than unadjusted estimates. Moderate adjustments (δ=0.9, τ=0.85) provided intermediate values approximately 1.3 times higher than baseline, representing our preferred specification that acknowledges likely visibility and reporting barriers while avoiding extreme assumptions.

```{r}
#| label: tbl-appendix-nsum-method
#| tbl-cap: "Sensitivity Analysis: NSUM Method and Adjustment Factor Comparison. All estimates use neighborhood bootstrap, SS weights, and N=980,000. Source: Authors' Own Work."
#| echo: false
#| warning: false
#| message: false

nsum_method_file <- here("output", "tables", "AppendixA4_nsum_method_comparison.csv")
if (file.exists(nsum_method_file)) {
  nsum_method_comp <- read_csv(nsum_method_file, show_col_types = FALSE)

  nsum_method_comp %>%
    kbl(
      col.names = c("NSUM Method", "Outcome", "Point Estimate",
                    "95% CI Lower", "95% CI Upper", "Prevalence (%)"),
      booktabs = TRUE,
      align = c("l", "l", "r", "r", "r", "l"),
      format.args = list(big.mark = ",")
    ) %>%
    kable_styling(
      latex_options = c("striped", "hold_position", "scale_down"),
      bootstrap_options = c("striped", "hover", "condensed"),
      full_width = FALSE,
      font_size = 8
    ) %>%
    pack_rows("GNSUM Symmetric", 1, 5) %>%
    pack_rows("MBSU Conservative (δ=0.8, τ=0.7)", 6, 10) %>%
    pack_rows("MBSU Moderate (δ=0.9, τ=0.85)", 11, 15) %>%
    pack_rows("MBSU No Adjustment (δ=1.0, τ=1.0)", 16, 20) %>%
    footnote(
      general = "MBSU = Modified Basic Scale-Up; GNSUM = Generalized Network Scale-Up Method; δ = transmission/barrier effect; τ = recall effect. Adjustment factors control for visibility and reporting biases in network-based estimation.",
      general_title = "Note:",
      footnote_as_chunk = TRUE
    )
} else {
  cat("NSUM method comparison file not found.\n")
}
```

#### Summary of Sensitivity Analyses

Across all 128 parameter combinations tested (4 bootstrap methods × 4 population sizes × 2 weight methods × 4 NSUM methods), prevalence estimates ranged from 0.83% to 4.08% for the five exploitation indicators. The most important source of variation was the choice of adjustment factors, with conservative adjustments producing estimates up to twice as high as unadjusted estimates. Bootstrap method, weight scheme, and population size assumptions had minimal impact on prevalence rates, demonstrating the robustness of our findings to these methodological choices.

For the main text analysis, we selected neighborhood bootstrap (providing conservative confidence intervals), SS weights (standard for RDS data), N=980,000 (based on EU labor force data), and MBSU with moderate adjustments (acknowledging likely barriers while avoiding extreme assumptions). This specification provides credible estimates while acknowledging uncertainty and avoiding both overly optimistic and overly pessimistic scenarios.

## Appendix C: Bootstrap Estimation for Network Scale-Up Using RDS Data {#app-3step}

### Introduction

When estimating the size or characteristics of a hidden population using the Network Scale-Up Method (NSUM), researchers typically assume a probability sample from the frame population.
However, in many applied settings—including hard-to-reach populations—data are collected via\*Respondent-Driven Sampling (RDS).
RDS introduces specific structural dependencies and inclusion probabilities that violate the assumptions of simple random sampling.

This presents a challenge: how can we correctly estimate uncertainty for NSUM estimates derived from an RDS sample?
As shown in @feeh16-generalized and @salg06-variance, the NSUM estimator depends crucially on inclusion weights $\pi_i$, which must reflect the sampling design.
When data are RDS-based, these weights are typically derived from known degree-based estimators such as RDS-II or Gile’s Successive Sampling (SS) weights.

To address this challenge, we propose a three-step bootstrap procedure for NSUM estimation using RDS data.
This approach is flexible, modular, and applicable across several classes of NSUM estimators.
It separates the issues of: 1.
How to resample an RDS chain (Step 1), 2.
How to recalculate sample-specific weights (Step 2), and 3.
How to apply a chosen NSUM estimator (Step 3).

------------------------------------------------------------------------

### Step 1: Resampling the RDS Sample

We begin by resampling from the observed RDS sample in a way that mimics the original recruitment structure.
Let the original sample be: $$
\mathcal{S} = \{i_1, i_2, \dots, i_n\}
$$ with recruitment chains and wave indicators.
Let $d_i$ denote self-reported degree for respondent $i$, and let the recruitment tree structure be encoded via seed/recruiter IDs.

#### Options for RDS Resampling

-   Tree Bootstrap: Sample entire recruitment trees (originating from seeds) with replacement. This respects the hierarchical recruitment structure and allows design effect estimation [@salg06-variance].
-   Successive Sampling Bootstrap (SSB): Sample with replacement according to inclusion probabilities derived from the SS model (@gile11-improv).
-   Neighborhood Bootstrap: Use ego-network topology to preserve recruitment ties and neighborhood structure (@yauc22-neighboor).
-   Chain Bootstrap: Each bootstrap replicate samples chains or subchains with replacement, preserving recruiter–recruitee links. This is implemented in `surveybootstrap::rds.boot.draw.chain()` and used in studies like @weir12-comparison.

Let $\mathcal{S}^{(b)}$ denote the sample drawn in bootstrap replicate $b$.

#### Resampling Procedure

We selected our first wave of par5cipants nonrandomly by convenience sampling. Mobile phone
numbers were used both to iden5fy seed par5cipants and to act as a unique iden5fier for those
whom they referred.
We used the publicly available ‘Neighboot’ bookstrapping procedure to es5mate confidence limits
from our sample (Yauck and Moodie, 2020). Bootstrapping contributes to overcoming the high
degree of uncertainty surrounding es5mates from samples generated through respondent-driven
sampling and allows beLer sta5s5cal inference, especially related to sampling variability (Baraﬀ et
al., 2016). These authors develop a mul5-level tree bootstrapping procedure based on resampling
recruitment trees that depends solely upon the structure of the sampled recruitment trees rather
than the aLributes being measured on the respondents. This allows es5ma5on of variability and
correla5ons between aLributes. Their tree bootstrap method can produce interval es5mates that are
able to account for the high variability of the RDS process, even when the design eﬀects are very
large, producing es5mates that are slightly conserva5ve – which is preferable in this situa5on. The
process involves a sample, without replacement from ini5al seed par5cipants, followed by
resampling from each of the selected seeds recruits and further resampling form second-level
recruits’ recruits and con5nues un5l there are no recruits remaining (Baraﬀ et al., 2016; Yauck et al.,
2022).More recently, however, Yauck et al. (2022) have raised concerns that the tree bootstrapping
method proposed by Baraﬀ et al., 2016) severely over es5mates uncertainty and, instead, propose a
neighborhood bootstrap method to quan5fy uncertainty in RDS. This is designed to capture the
‘local’ neighborhood depdendence by including the selected recruiters’ recruits. Yauck et al., (2022)
argue that this approach improves upon previously advocated approaches because the ‘local’
neighbors’ 5es are present in any full, unobserved network of the target popula5on. This method is
par5cularly suitable for our study, since it oﬀers computa5onal eﬃciencies which yield confidence
intervals with conserva5ve coverages for small sample sizes and is based on resampling recruited
individuals and their observed neighbors -defined as those individuals with whom they are directly
connected within the RDS tree. Yauck et al.’s method relies on the following assump5ons: i) social
connec5ons are reciprocal and ii) an individual within the network can reach another individual
through a finite set of connec5ons. Their bootstrap method is based upon sequen5ally resampling
recruiters and their recruits and can be described in two main steps: step 1 involved the random
selec5on, with replacement of the number of recruiters within the RDS sample. Step 2 then includes
the selected recruiters and their corresponding recruits in the bootstrap sample.
The method allows the construc5on of calibrated interval es5mates. Unlike other methods, the
advantages of this approach include its ability to derive es5mates from a single bootstrap sample for
any number of aLributes.
Limita5ons
Baraﬀ et al. (2016)’s approach relies on a series of simplifying assump5ons, namely: i) the social
network is finite and connected ii) network connec5ons are reciprocal, not directed [I believe this to
be true of the respondents in our study] iii) recruits accurately report their network degree [this is
facilitated by the concrete request to provide a count of domes5c workers contacts within their
mobile phone – thereby minimising recall error[ iv) recruitment coupons are distributed uniformly at
random to neighbours in the network [in our study, the research team managed the distribu5on of
the survey link to those suggested by our seeds and respondents from earlier waves] v) that
individuals may be recruited into the sample more than once. Baraﬀ et al., note that this laLer
assump5on par5cularly does not relate to the reality of RDS in prac5ce.
References
Baraﬀ, Aaron J., Tyler H. McCormick, and Adrian E. Ra`ery. 2016. “Es5ma5ng Uncertainty in
Respondent-Driven Sampling Using a Tree Bootstrap Method.” Proceedings of the Na5onal Academy
of Sciences of the United States of America 113 (51): 14668–73.
hLps://doi.org/10.1073/pnas.1617258113.
Feehan, Dennis M., and MaLhew J. Salganik. 2016. “Online Appendix: Generalizing the Network
Scale-up Method.” Sociological Methodology 46 (1): 153–86.
hLps://doi.org/10.1177/0081175016665425.
Mamadou Yauck, Erica E M Moodie, Herak Apelian, Alain Fourmigue, Daniel Grace, Trevor A
Hart, Gilles Lambert, Joseph Cox, Neighborhood Bootstrap for Respondent-Driven
Sampling, Journal of Survey Statistics and Methodology, Volume 10, Issue 2, April 2022, Pages
419–438, https://doi.org/10.1093/jssam/smab057
Yauck, Mamadou, and Erica E. M. Moodie. 2022. Neighboot: Neighborhood Bootstrap
Method for RDS (version 1.0.1). https://cran.r-
project.org/web/packages/Neighboot/index.html.

------------------------------------------------------------------------

### Step 2: Recalculating Weights

NSUM estimators require inclusion weights $\pi_i$ or their inverses $w_i = 1 / \pi_i$.
Because bootstrap samples differ in composition and recruitment pattern, these weights must be recomputed for each replicate.

#### General Structure

For each replicate $b$, construct: - $\mathcal{S}^{(b)}$: resampled respondent IDs - $d_i^{(b)}$: degree reports in replicate - $\pi_i^{(b)}$: estimated inclusion probabilities

#### Weighting Options

-   RDS-II Weights (@volz08-simple): $$
    w_i^{(b)} \propto \frac{1}{d_i^{(b)}}
    $$

-   SS Weights (@gile11-improv): Incorporate sampling fraction and frame size $N_F$.
    Computed numerically via successive sampling approximation.

Let $\mathbf{X}_i$ denote covariates (e.g. traits, degree, indicator of hidden population membership), which are retained from the original data and passed to Step 3.

------------------------------------------------------------------------

### Step 3: NSUM Estimation

#### Step 3: NSUM Estimation on Resampled and Reweighted Data

Given a bootstrap sample $\mathcal{S}^{(b)}$, we estimate the size of the hidden population $N_H$ using one of several NSUM estimators.
All estimators rely on weighted sums of out-reports and degree.

##### (a) Generalized NSUM (GNSUM)

As described in @feeh16-generaling, GNSUM estimates:

$$\hat{N}_H^{(b)} = \left( \frac{\sum_{i} \frac{y_{i,H}}{\pi_i^{(b)}}}{\sum_{i} \frac{d_i}{\pi_i^{(b)}}} \right) \cdot N_F$$

Where:

-   $y_{i,H}$: number of known alters in the hidden population,

-   $d_i$: degree (known network size, e.g. from Q13),

-   $N_F$: size of the frame population (e.g. domestic workers in UK).

##### (b) GNSUM with Symmetric Visibility (for Hidden Members in RDS)

In your context, some RDS respondents are ex post identified as members of the hidden population.
Under the symmetric visibility assumption, if $i \in H$, we assume the probability that $i$ knows $j$ is the same as $j$ knows $i$.
This allows in-reports to be incorporated.

Let:

-   $I_H(i) = 1$ if $i \in H$, 0 otherwise

-   $y_{i}^{\text{in}}$: number of other hidden members who report knowing $i$

Then the estimator becomes:

$$\hat{N}_H^{(b)} = \left( \frac{\sum_{i} \frac{y_{i,H} + I_H(i) \cdot y_{i}^{\text{in}}}{\pi_i^{(b)}}}{\sum_{i} \frac{d_i}{\pi_i^{(b)}}} \right) \cdot N_F$$

##### (c) Modified Basic Scale-Up (MBSU)

This estimator adjusts for key reporting biases via three correction factors:

$$\hat{N}_H^{(b)} = \left( \frac{\sum_{i} \frac{y_{i,H}}{\pi_i^{(b)}}}{\sum_{i} \frac{d_i}{\pi_i^{(b)}}} \right) \cdot N_F \cdot \frac{1}{\delta \cdot \tau \cdot \rho}$$

Where:

-   $\delta$: Transmission bias (probability respondent is aware of alter’s status),

-   $\tau$: Barrier effect (social mixing between hidden and frame population),

-   $\rho$: Popularity bias (relative visibility of hidden population members).

These values can be:

-   Estimated using known subpopulations (e.g., alter groups with known size),

-   Set by expert elicitation,

-   Scanned in sensitivity analysis.

##### (d) Model-Based NSUM

Bayesian implementations (e.g. @malt15-estimating) model:

-   Degree distributions,

-   Reporting error,

-   Group visibility,

-   Hidden population size.

They yield a posterior distribution over $N_H$, and uncertainty is embedded within the model.

------------------------------------------------------------------------

This step applies an NSUM estimator to the bootstrap sample $\mathcal{S}^{(b)}$ using the recalculated weights $w_i^{(b)}$ and responses $y_{i,H}$, where $y_{i,H}$ is the number of known contacts respondent $i$ has in hidden population $H$.

Let $N_F$ denote the frame population size (assumed known), and let $d_i$ be the degree of respondent $i$.

#### Generalized NSUM Estimator (GNSUM)

The weighted GNSUM estimator is:

$$
\hat{N}_H^{(b)} = \frac{\sum_{i \in \mathcal{S}^{(b)}} \frac{y_{i,H}}{\pi_i^{(b)}}}{\sum_{i \in \mathcal{S}^{(b)}} \frac{d_i}{\pi_i^{(b)}}} \cdot N_F
$$

This estimator assumes proportional mixing and equal visibility.

------------------------------------------------------------------------

#### Symmetric Visibility Variant

In our setting, some RDS respondents can be identified *ex post* as members of the hidden population $H$.
Denote this set $\mathcal{H} \subseteq \mathcal{S}$.
Under the assumption of symmetric visibility, we define:

$$
\hat{v}_{H} = \frac{1}{|\mathcal{H}|} \sum_{j \in \mathcal{H}} \frac{y_{j,F}}{d_j}
$$

That is, the average proportion of alters known by members of $H$ who are in the frame population $F$.
Incorporating this, the symmetric visibility GNSUM becomes:

#### Step 4: Aggregating Bootstrap Estimates

After $B$ replicates:

$$\hat{N}_H^{(1)}, \dots, \hat{N}_H^{(B)}$$

We compute:

-   Point estimate: $\bar{N}_H = \frac{1}{B} \sum_b \hat{N}_H^{(b)}$

-   Standard error: sample SD

-   95% CI: empirical percentiles (e.g., 2.5%, 97.5%)

------------------------------------------------------------------------

------------------------------------------------------------------------

#### Step 2: Recalculate Inclusion Probabilities

RDS produces samples with unknown and unequal probabilities of inclusion, which must be corrected when used in NSUM estimation.
This is achieved by estimating the probability $\pi_i^{(b)}$ that each individual $i$ in bootstrap replicate $b$ is included in the sample, conditional on their degree and position in the recruitment tree.

These probabilities are used to generate sampling weights $w_i^{(b)} = 1/\pi_i^{(b)}$, which are passed into NSUM estimators.

##### Estimation Methods

(a) RDS-II (Volz-Heckathorn) Weights\
Assumes the probability of selection is proportional to the respondent's degree:

$$\pi_i \propto d_i \quad \Rightarrow \quad w_i = \frac{1}{d_i}$$

These weights are normalized post hoc.
This method is simple but does not account for homophily or finite population correction (@volz08-rds).

(b) Gile’s Successive Sampling (SS) Weights\
This method assumes RDS approximates successive sampling without replacement.
The inclusion probabilities are computed by simulating from a known or assumed population size $N$.
This method is implemented in `RDS::gile.ss.weights()` and adjusts for:

-   Finite population effects,

-   Degree-based sampling,

-   Sample depletion over waves.

(c) User-Defined or Model-Based Weights\
Researchers may define weights using alternative models or Bayesian simulations.
This includes post-stratification or fitting full generative models of the RDS process.

##### Software Example (R)

``` r
library(RDS)
rd <- as.rds.data.frame(boot_sample, id = "id", recruiter.id = "recruiter.id")
boot_sample$ss_weight <- gile.ss.weights(rd, N = 980000)
boot_sample$vh_weight <- rds.weights(rd, weight.type = "RDS-II")
```

The output is a new dataset with respondent traits, degrees, and updated $\pi_i^{(b)}$, which are used in Step 3.

------------------------------------------------------------------------

------------------------------------------------------------------------

#### 5. References

-   @feeh16-generalizing

-   @salf06-variance

-   @gile11-inference

-   @volz08-rds

-   @malt15-estimating

-   @yauc22-neighboot

-   @weir12-comparison

-   @salg06-variance

-   @rust96-rescaled

-   @rao88-resampling
